{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import kerastuner as kt\n",
    "from contextlib import redirect_stdout\n",
    "import shutil\n",
    "import locale\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8') #This is needed to convert string values of type 1,999.99 \n",
    "                                               #to float 1999.99\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load locally stored data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define where are the datasets\n",
    "\n",
    "#Paths for data with market info\n",
    "path = os.getcwd()+\"/exper_files/datasets/\" #Here they are datasets from yahoo\n",
    "#path = os.getcwd()+\"/exper_files/coinmarket/\" #Here they are datasets from coinmarket\n",
    "\n",
    "#Paths for data with social info\n",
    "social_path = os.getcwd()+\"/exper_files/social_datasets/cryptocompare/\" #Define where are the datasets from cryptocompare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creation(crypto_list, pth, social_pth, social_use_flag):\n",
    "    datasets = {} #Store all datasets here\n",
    "    social_datasets = {} #Store all datasets with social media information here\n",
    "    \n",
    "    min_dates = {} #Store all minimum dates here\n",
    "    max_dates = {} #Store all maximum dates here\n",
    "    \n",
    "    datasets_list = os.listdir(pth) #Find all dataset\n",
    "    social_datasets_list = os.listdir(social_pth) #Find all dataset with social media information\n",
    "    \n",
    "    splitted_path = path.split('/')\n",
    "    if splitted_path[-2] == 'coinmarket':\n",
    "        type_of_file = '.txt'\n",
    "    \n",
    "    elif splitted_path[-2] == 'datasets':\n",
    "        type_of_file = '.csv'\n",
    "        \n",
    "    \n",
    "    social_crypto_list = [elem+'.csv' for elem in crypto_list]\n",
    "    crypto_list = [elem+type_of_file for elem in crypto_list]\n",
    "    \n",
    "    \n",
    "    for dataset in datasets_list:\n",
    "        if dataset.endswith(type_of_file) and (dataset) in crypto_list:\n",
    "\n",
    "            name = dataset.split(\".\")\n",
    "            dataset_name = name[0]\n",
    "            \n",
    "            if splitted_path[-2] == 'datasets':\n",
    "                \n",
    "                datasets[dataset_name] = pd.read_csv(pth + dataset) \n",
    "\n",
    "                datasets[dataset_name]['Date'] = pd.to_datetime(datasets[dataset_name]['Date']) #Dataset from yahoo\n",
    "                                                                                            #is stored ia .csv file.\n",
    "                    \n",
    "                datasets[dataset_name].rename(columns={'Adj Close':dataset_name+'Adj_Close'}) #Space will cause troubles\n",
    "                \n",
    "            \n",
    "            elif splitted_path[-2] == 'coinmarket':  \n",
    "                    \n",
    "                lines = []\n",
    "                with open(pth + dataset) as f: #Dataset from coinmarket is stored in a .txt file, so we need to read it\n",
    "                                               #line by line.\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                initial_columns = lines[0].split(\"\\t\") #Split the first line to individual words. The first line \n",
    "                                                       #contains the column names. \n",
    "                columns = []\n",
    "                for col in initial_columns:\n",
    "                    clear_col = col.split('*') #Some column names contains * or **, so we need to exclude them\n",
    "                    clear_col = clear_col[0].split('\\n') #The last element cointains a \\n\n",
    "                    \n",
    "                    if clear_col[0] == 'Market Cap':\n",
    "                        clear_col[0] = 'Market_Cap' #Space will cause troubles\n",
    "                    columns.append(clear_col[0])\n",
    "                \n",
    "                df = pd.DataFrame(columns=columns) #Define column names\n",
    "                \n",
    "                \n",
    "                for line in range(1, len(lines)):\n",
    "                    \n",
    "                    splitted_line = lines[line].split(\"\\t\") #Split each line to individual numbers\n",
    "                    \n",
    "                    for elem in range(len(splitted_line)):\n",
    "                        clear_elem = splitted_line[elem].split('$') #All number cointains a $ (except Date) so we need \n",
    "                                                                    #throw it away.\n",
    "                        \n",
    "                        if len(clear_elem) == 1:\n",
    "                            splitted_line[elem] = pd.to_datetime(clear_elem[0])#Tranform each Date to 'datetime' type\n",
    "                            \n",
    "                        else:\n",
    "                            clear_elem[1] = clear_elem[1].split('\\n')\n",
    "                            splitted_line[elem] = locale.atof(clear_elem[1][0])\n",
    "                    \n",
    "                    #Append each line to the dataframe\n",
    "                    row_to_append = pd.Series(splitted_line, index=columns)                    \n",
    "                    df = df.append(row_to_append, ignore_index=True)\n",
    "                \n",
    "                #Invert the sorting of values to ascending based on 'Date'\n",
    "                df = df.sort_values(by=['Date']).reset_index().drop(['index'], axis=1)\n",
    "                datasets[dataset_name] = df.copy()\n",
    "            \n",
    "            #There are a few missing values, so let fill them with the previous value\n",
    "            datasets[dataset_name].fillna(method='ffill', inplace=True)\n",
    "\n",
    "            #Create new columns 'close_off_high' and 'volatility' in order to make predictions more accurate:\n",
    "            kwards = {'close_off_high': lambda x: 2 * (x['High'] - x['Close']) / (x['High'] - x['Low']) - 1,\n",
    "              'volatility': lambda x: (x['High'] - x['Low']) / (x['Open'])\n",
    "              }\n",
    "\n",
    "            datasets[dataset_name] = datasets[dataset_name].assign(**kwards)\n",
    "            \n",
    "            datasets[dataset_name].fillna(-1, inplace=True) #Fill possible NaN close_off_high values with -1\n",
    "                                                            #Because NaN values caused by (0/0)-1\n",
    "            \n",
    "\n",
    "            first_date = pd.to_datetime(datasets[dataset_name]['Date'][0])\n",
    "            min_dates[dataset_name]=first_date\n",
    "            \n",
    "            last_date = pd.to_datetime(datasets[dataset_name]['Date'].iloc[-1])\n",
    "            max_dates[dataset_name] = last_date\n",
    "            \n",
    "    \n",
    "    \n",
    "    #Get social media information for each coin from the corresponding csv\n",
    "    if social_use_flag:\n",
    "        for dataset in social_datasets_list:\n",
    "            if dataset.endswith(\".csv\") and (dataset) in social_crypto_list:\n",
    "\n",
    "                name = dataset.split(\".\")\n",
    "                dataset_name = name[0]\n",
    "\n",
    "                social_datasets[dataset_name] = pd.read_csv(social_pth + dataset) \n",
    "\n",
    "                social_datasets[dataset_name]['time'] = pd.to_datetime(social_datasets[dataset_name]['time'])\n",
    "\n",
    "                #Drop first column which is an unused index\n",
    "                social_datasets[dataset_name] = social_datasets[dataset_name].iloc[:, 1:]\n",
    "\n",
    "                #We observed that there are many zero rows at social media datasets.\n",
    "                #We should find the first row which is non-zero\n",
    "                res = [next(((j, i) for i, j in enumerate(social_datasets[dataset_name][col]) if j != 0), (0, 0)) \n",
    "                       for col in social_datasets[dataset_name] if col != 'time']\n",
    "\n",
    "                #Get all columns except 'time'\n",
    "                columns_except_time = [col for col in social_datasets[dataset_name].columns if col != 'time']\n",
    "\n",
    "                #Store the index of each column with the first non-zero element\n",
    "                df_res = pd.DataFrame(res, columns=['value', 'position'], index=columns_except_time)\n",
    "\n",
    "                #Get the minimum of these indices\n",
    "                first_non_zero_row = df_res['position'].min()\n",
    "\n",
    "\n",
    "                first_date = pd.to_datetime(social_datasets[dataset_name]['time'][first_non_zero_row])\n",
    "                if first_date >  min_dates[dataset_name]:\n",
    "                     min_dates[dataset_name] = first_date\n",
    "\n",
    "                last_date = pd.to_datetime(social_datasets[dataset_name]['time'].iloc[-1])\n",
    "                if last_date < max_dates[dataset_name]:\n",
    "                    max_dates[dataset_name] = last_date\n",
    "            \n",
    "    \n",
    "    \n",
    "    max_date = max(min_dates.values(), key=lambda v: v)\n",
    "    min_date = min(max_dates.values(), key=lambda v: v)\n",
    "\n",
    "    #Drop all the data which are prior to max_date and later to min_date\n",
    "    for dataset in datasets:\n",
    "        datasets[dataset] = datasets[dataset][(datasets[dataset]['Date'] >= max_date) & \n",
    "                                              (datasets[dataset]['Date'] <= min_date)]\n",
    "        \n",
    "    for dataset in social_datasets:\n",
    "        social_datasets[dataset] = social_datasets[dataset][(social_datasets[dataset]['time'] >= max_date) & \n",
    "                                                            (social_datasets[dataset]['time'] <= min_date)]\n",
    "\n",
    "\n",
    "    #Compute the average and standard deviation of 'Close' value for the last 7-days and 30-days(month): \n",
    "    for dataset in datasets:\n",
    "\n",
    "        temp = datasets[dataset].copy()\n",
    "\n",
    "        #Drop the first 30 days to be able to compute average and standard deviation of month for the rows of the table\n",
    "        temp = temp[29:]\n",
    "\n",
    "        temp['mean_7days_Close'] = datasets[dataset]['Close'].rolling(window=7).mean()\n",
    "\n",
    "        temp['mean_month_Close'] = datasets[dataset]['Close'].rolling(window=30).mean()\n",
    "\n",
    "        temp['std_7days_Close'] = datasets[dataset]['Close'].rolling(window=7).std()\n",
    "\n",
    "        temp['std_month_Close'] = datasets[dataset]['Close'].rolling(window=30).std()\n",
    "\n",
    "        datasets[dataset] = temp.copy()\n",
    "        \n",
    "    \n",
    "    #Drop the first 30 days of 'social_datasets' to be aligned with 'datasets'\n",
    "    for dataset in social_datasets:\n",
    "            social_datasets[dataset] = social_datasets[dataset][29:]\n",
    "          \n",
    "\n",
    "\n",
    "    #Rename the columns and concatenate all datasets to one \n",
    "    count = 0\n",
    "    for dataset in datasets:\n",
    "\n",
    "        datasets[dataset] = datasets[dataset].rename(columns=lambda x: dataset+'_'+x)\n",
    "        datasets[dataset] = datasets[dataset].rename(columns={dataset+'_Date': 'Date'})                                                   \n",
    "        \n",
    "        if count == 0:\n",
    "            \n",
    "            date_col = (datasets[dataset]['Date'].reset_index()).drop(['index'], axis=1)\n",
    "            \n",
    "            \n",
    "        datasets[dataset] = ((datasets[dataset].drop(['Date'], axis=1)).reset_index()).drop(['index'], axis=1)    \n",
    "                    \n",
    "    \n",
    "    for dataset in social_datasets:\n",
    "        \n",
    "        social_datasets[dataset] = social_datasets[dataset].rename(columns=lambda x: dataset+'_'+x)\n",
    "        \n",
    "        social_datasets[dataset] = ((social_datasets[dataset].drop([dataset+'_time'], axis=1)).reset_index()).drop(['index'], \n",
    "                                                                                                          axis=1) \n",
    "\n",
    "    \n",
    "    \n",
    "    #Concatenate all datasets to one \n",
    "    whole_market_dataset = pd.concat([datasets[dataset] for dataset in datasets], axis=1)\n",
    "    if len(social_datasets) == len(datasets):\n",
    "        whole_social_dataset = pd.concat([social_datasets[dataset] for dataset in social_datasets], axis=1)\n",
    "        whole_dataset = pd.concat([date_col, whole_market_dataset, whole_social_dataset], axis=1)\n",
    "    else:\n",
    "        whole_dataset = pd.concat([date_col, whole_market_dataset], axis=1)\n",
    "    \n",
    "   \n",
    "    return whole_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training, validation and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(perc_train_set, perc_val_set, currency_data):\n",
    "        \n",
    "        #Compute the date to split the dataset into training and validation_test set based on 'perc_train_set'\n",
    "        splt_date_train = currency_data.iloc[round(currency_data.shape[0] * perc_train_set)]['Date']\n",
    "        \n",
    "        #Split the dataset into trainning and validation_test set\n",
    "        tr_set, val_tst_set = currency_data[currency_data['Date'] < splt_date_train], \\\n",
    "                         currency_data[currency_data['Date'] >= splt_date_train]\n",
    "        \n",
    "        #Compute the date to split the val_tst_set into validation and test set based on 'perc_val_set'\n",
    "        splt_date_val = val_tst_set.iloc[round(val_tst_set.shape[0] * perc_val_set)]['Date']\n",
    "\n",
    "        #Split the val_tst_set into validation and test set        \n",
    "        val_set, tst_set = val_tst_set[val_tst_set['Date'] < splt_date_val], \\\n",
    "                            val_tst_set[val_tst_set['Date'] >= splt_date_val]\n",
    "        \n",
    "        return tr_set, val_set, tst_set, splt_date_train, splt_date_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will normalize training, validation and test inputs with MixMaxScaler.\n",
    "\n",
    "\n",
    "#Define classification task\n",
    "\n",
    "Also, here we will define labels for the classification task. If a close value of the target coin *p* in a current date *t* (*p(t)*) is greater or equal than the 99% of the average close value (*99% avg(p(t))*) of the last 30 days (*t-30*), then this is a positive label (*pos*), else it is a negative label (*neg*). In a more formal way:\n",
    "\n",
    "if: p(t) >= 99% avg(p(t)), where avg(p(t)) = sum(p(t-i))[for i in range(1, 30)], then *pos* \n",
    "\n",
    "else: *neg*\n",
    "\n",
    "\n",
    "This kind of labels will be created for *pred_range* (5) days ahead for every *pred_range* (5) days.\n",
    "\n",
    "So, the number of output nodes of the Neural Network will be equal to pred_range*2 (5*2=10), because for each day it has to be decided which of the nodes of 1 and 0 is the correct class. Therefore, for each sample to be predicted there will be the following classes: *class_day(1)_pos*, *class_day(1)_neg*, *class_day(2)_pos*, *class_day(2)_neg*, ..., *class_day(pred_range)_pos*, *class_day(pred_range)_neg*.\n",
    "\n",
    "This means that for each sample to be predicted, we should keep as the predicted label of each day the one with the the greater probability among *class_day(i)_pos*, *class_day(i)_neg*.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "\n",
    "def normalize_in_out(prd_range, wind_len, tr_set, val_set, tst_set, feats, coin_targ, crypto_list):\n",
    "    \n",
    "    \n",
    "    #Scaling\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)) #Scaler for all columns\n",
    "    \n",
    "    \n",
    "    tr_set = tr_set.drop(['Date'], axis=1)\n",
    "    #transformed_tr_set_values = np.log(tr_set.values)#((tr_set.values**(-3))-1)/-3\n",
    "    #transformed_tr_set_values[transformed_tr_set_values == -inf] = 0\n",
    "    train_scaled_data = pd.DataFrame(scaler.fit_transform(tr_set.values), columns=tr_set.columns, #scaler.fit_transform(transformed_tr_set_values)\n",
    "                                     index=training_set.index) #Training set fit and transform\n",
    "\n",
    "    val_set = val_set.drop(['Date'], axis=1) #Keep initial validation set to use average of month close values\n",
    "    #transformed_val_set_values = np.log(val_set.values)#((val_set.values**(-3))-1)/-3\n",
    "    #transformed_val_set_values[transformed_val_set_values == -inf] = 0\n",
    "    val_scaled_data = pd.DataFrame(scaler.transform(val_set.values), columns=val_set.columns, #scaler.transform(transformed_val_set_values)\n",
    "                                  index=val_set.index) #Validation set just transform\n",
    "\n",
    "    tst_set = tst_set.drop(['Date'], axis=1) #Keep initial test set to use average of month close values\n",
    "    #transformed_tst_set_values = np.log(tst_set.values)#((tst_set.values**(-3))-1)/-3\n",
    "    #transformed_tst_set_values[transformed_tst_set_values == -inf] = 0\n",
    "    test_scaled_data = pd.DataFrame(scaler.transform(tst_set.values), columns=tst_set.columns, #scaler.transform(transformed_tst_set_values)\n",
    "                                   index=tst_set.index) #Test set just tranform\n",
    "\n",
    "    \n",
    "    all_feats = tr_set.columns #Get all features\n",
    "    feats = [crypto+\"_\"+feat for crypto in crypto_list for feat in feats] #Get the features in the appropriate format \n",
    "                                                                          #(e.g 'Close' --> 'BTC-USD_Close')\n",
    "    \n",
    "    \n",
    "    #Normalize training inputs\n",
    "    LSTM_tr_in = []\n",
    "    for i in range(len(train_scaled_data) - wind_len):\n",
    "        tmp_set = train_scaled_data[i:(i + wind_len)].copy()\n",
    "        \n",
    "        for col in all_feats:\n",
    "            if col not in feats:\n",
    "                tmp_set = tmp_set.drop([col], axis=1) #Drop the feature that will not be used\n",
    "\n",
    "        LSTM_tr_in.append(tmp_set)\n",
    "    \n",
    "    #Transform from DataFrame to numpy array\n",
    "    LSTM_tr_in = [np.array(LSTM_tr_i) for LSTM_tr_i in LSTM_tr_in]\n",
    "    LSTM_tr_in = np.array(LSTM_tr_in)\n",
    "    \n",
    "    \n",
    "    #Normalize validation inputs\n",
    "    LSTM_val_in = []\n",
    "    for i in range(len(val_scaled_data) - wind_len):\n",
    "        tmp_set = val_scaled_data[i:(i + wind_len)].copy()\n",
    "        \n",
    "        for col in all_feats:\n",
    "            if col not in feats:\n",
    "                tmp_set = tmp_set.drop([col], axis=1) #Drop the feature that will not be used\n",
    "\n",
    "        LSTM_val_in.append(tmp_set)\n",
    "        \n",
    "    #Transform from DataFrame to numpy array\n",
    "    LSTM_val_in = [np.array(LSTM_val_i) for LSTM_val_i in LSTM_val_in]\n",
    "    LSTM_val_in = np.array(LSTM_val_in)\n",
    "    \n",
    "    \n",
    "    #Normalize test inputs\n",
    "    LSTM_test_in = []\n",
    "    for i in range(len(test_scaled_data) - wind_len):\n",
    "        tmp_set = test_scaled_data[i:(i + wind_len)].copy() \n",
    "        \n",
    "        for col in all_feats:\n",
    "            if col not in feats:\n",
    "                tmp_set = tmp_set.drop([col], axis=1) #Drop the feature that will not be used\n",
    "\n",
    "        LSTM_test_in.append(tmp_set)\n",
    "    \n",
    "    \n",
    "    #Transform from DataFrame to numpy array\n",
    "    LSTM_test_in = [np.array(LSTM_test_i) for LSTM_test_i in LSTM_test_in]\n",
    "    LSTM_test_in = np.array(LSTM_test_in)\n",
    "    \n",
    "    \n",
    "    #Create LSTM outputs labels for training. Each output is corresponded to the days which are going to \n",
    "    #be predicted (pred_range)\n",
    "    LSTM_rangd_train_out = []\n",
    "    for i in range(wind_len, len(train_scaled_data[coin_targ+'_Close']) - prd_range):\n",
    "        \n",
    "        labels = [] #Create a list with pred_range*2 1s and 0s according with the true value of each class\n",
    "                    #It is obvious that of a day is pos, it cannot be also negative. So, the ground truth of each\n",
    "                    #day classes it should be 0,1 or 1,0.\n",
    "        \n",
    "        for j in range(i, i+prd_range):\n",
    "            \n",
    "            if tr_set[coin_targ+'_Close'][j] >= (tr_set[coin_targ+'_mean_month_Close'][j])*0.99: \n",
    "                labels.extend([1, 0])\n",
    "                \n",
    "            else:\n",
    "                labels.extend([0, 1])\n",
    "        \n",
    "        \n",
    "        LSTM_rangd_train_out.append(labels)\n",
    "\n",
    "    LSTM_rangd_train_out = np.array(LSTM_rangd_train_out)\n",
    "    \n",
    "    \n",
    "    #Create LSTM outputs labels for validation. Each output is corresponded to the days which are going to \n",
    "    #be predicted (pred_range)    \n",
    "    LSTM_rangd_val_out = []\n",
    "    \n",
    "    val_set = val_set.reset_index().drop(['index'], axis=1) #Reset index to start from 0\n",
    "    \n",
    "    \n",
    "    for i in range(wind_len, len(val_scaled_data[coin_targ+'_Close']) - prd_range):\n",
    "        \n",
    "        labels = []\n",
    "        \n",
    "        for j in range(i, i+prd_range):\n",
    "            \n",
    "            if val_set[coin_targ+'_Close'][j] >= (val_set[coin_targ+'_mean_month_Close'][j])*0.99: \n",
    "                labels.extend([1, 0])\n",
    "            \n",
    "            else:\n",
    "                labels.extend([0, 1])\n",
    "            \n",
    "        LSTM_rangd_val_out.append(labels)\n",
    "    \n",
    "    LSTM_rangd_val_out = np.array(LSTM_rangd_val_out)\n",
    "    \n",
    "    \n",
    "    #Create LSTM outputs labels for test. Each output is corresponded to the days which are going to \n",
    "    #be predicted (pred_range)    \n",
    "    LSTM_rangd_test_out = []\n",
    "    \n",
    "    tst_set = tst_set.reset_index().drop(['index'], axis=1) #Reset index to start from 0\n",
    "    \n",
    "    for i in range(wind_len, len(test_scaled_data[coin_targ+'_Close']) - prd_range):\n",
    "        \n",
    "        labels = []\n",
    "        \n",
    "        for j in range(i, i+prd_range):\n",
    "            \n",
    "            if tst_set[coin_targ+'_Close'][j] >= (tst_set[coin_targ+'_mean_month_Close'][j])*0.99: \n",
    "                labels.extend([1, 0])\n",
    "            \n",
    "            else:\n",
    "                labels.extend([0, 1])\n",
    "            \n",
    "        LSTM_rangd_test_out.append(labels)\n",
    "    \n",
    "    LSTM_rangd_test_out = np.array(LSTM_rangd_test_out)\n",
    "    \n",
    "    \n",
    "    return LSTM_rangd_train_out, LSTM_rangd_val_out, LSTM_rangd_test_out, LSTM_tr_in, LSTM_val_in, LSTM_test_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and build model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM,GRU\n",
    "from keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def build_and_train_model(inputs, outputs, output_size, val_inputs, val_outputs, GRU_neurons, first_dense_neurons, \n",
    "                          first_dropout, second_dense_neurons, second_dropout, prd_range, epochs, \n",
    "                          batch_size, early_stop_patience, \n",
    "                          activ_func=\"sigmoid\", dropout=0.25, loss=\"binary_crossentropy\", optimizer=\"adam\"):\n",
    "\n",
    "    def build_model():\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(GRU(GRU_neurons, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "\n",
    "        model.add(Dense(units=first_dense_neurons))\n",
    "        \n",
    "        model.add(Dropout(first_dropout))\n",
    "        \n",
    "        model.add(Dense(units=second_dense_neurons))\n",
    "\n",
    "        model.add(Dropout(second_dropout))\n",
    "        \n",
    "        model.add(Dense(units=output_size))\n",
    "        \n",
    "        model.add(Activation(activ_func))\n",
    "        \n",
    "        #optimizer = tf.keras.optimizers.Adam(\n",
    "        #learning_rate=0.00001)\n",
    "\n",
    "        model.compile(loss=loss, optimizer=optimizer, \n",
    "                      metrics=[tfa.metrics.F1Score(average='macro', num_classes=output_size)])\n",
    "        return model\n",
    "\n",
    "    \n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stop_patience)\n",
    "    \n",
    "    rnged_btcoin_model = build_model()\n",
    "    rnged_hist = rnged_btcoin_model.fit(inputs[:-prd_range], outputs,\n",
    "                                       validation_data=(val_inputs[:-prd_range], val_outputs), callbacks=[stop_early],\n",
    "                                        epochs=epochs, batch_size=batch_size, verbose=2, shuffle=True, workers=8)\n",
    "    \n",
    "    return rnged_btcoin_model, rnged_hist  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create binary cross entropy loss plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(rangd_h, path_to_sav, target_cn, loss='loss'):\n",
    "    \n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(25, 10))\n",
    "\n",
    "    ax1.plot(rangd_h.epoch, rangd_h.history[loss], color='b', label='Loss')\n",
    "    ax1.plot(rangd_h.epoch, rangd_h.history['val_'+loss], color='orange', label='Val_loss')\n",
    "    ax1.set_xticks(range(0, len(rangd_h.epoch)))\n",
    "    ax1.set_title('Training Error')\n",
    "    ax1.set_ylabel('Binary Cross entropy', fontsize=12)\n",
    "    ax1.set_xlabel('#Epoch', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.savefig(path_to_sav+\"/\"+target_cn+'_binary_cross_entropy.png')\n",
    "    plt.close(fig)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create F1 macro plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_F1_macro_plot(rangd_h, path_to_sav, target_cn, metric='f1_score'):\n",
    "    \n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(25, 10))\n",
    "\n",
    "    ax1.plot(rangd_h.epoch, rangd_h.history[metric], color='b', label='F1_macro')\n",
    "    ax1.plot(rangd_h.epoch, rangd_h.history['val_'+metric], color='orange', label='Val_F1_macro')\n",
    "    ax1.set_xticks(range(0, len(rangd_h.epoch)))\n",
    "    ax1.set_title('F1 macro score')\n",
    "    ax1.set_ylabel('Score', fontsize=12)\n",
    "    ax1.set_xlabel('#Epoch', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.savefig(path_to_sav+\"/\"+target_cn+'_F1_macro.png')\n",
    "    plt.close(fig)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def create_conf_matrix(prds, LSTM_ranged_validation_outs, trgt_coin, pretrain_model_coin, path_to_sav):\n",
    "    \n",
    "    #Convert one_hot_representations to numeric(0 or 1) labels\n",
    "    y_preds = []\n",
    "    for i in range(prds.shape[0]):\n",
    "        if np.round(prds[i]).tolist() == [1, 0]:\n",
    "            y_preds.append(1)\n",
    "        else:\n",
    "            y_preds.append(0)\n",
    "\n",
    "    y_true = []\n",
    "    for i in range(LSTM_ranged_validation_outs.shape[0]):\n",
    "        if np.round(LSTM_ranged_validation_outs[i]).tolist() == [1, 0]:\n",
    "            y_true.append(1)\n",
    "        else:\n",
    "            y_true.append(0)\n",
    "\n",
    "    \n",
    "    #Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_preds)\n",
    "    \n",
    "\n",
    "    labels = ['Decrease', 'Increase']\n",
    "    df_cm = pd.DataFrame(cm, index = labels,\n",
    "                      columns = labels)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.xlabel(\"Predicted\", fontsize=30)\n",
    "    plt.ylabel(\"Actuals\", fontsize=30) \n",
    "    plt.title(trgt_coin + ' predictions using pretrained model with '+pretrain_model_coin+ ' data', fontsize=20)\n",
    "    plt.savefig(path_to_sav+\"/\"+'conf_matrix.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define tuning and building of model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Model with CNN layers, followed by LSTM layers, followed by Dense layers #####################\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "def model_tuning(inputs, outputs, output_size, validation_inputs, validation_outputs, epochs, early_stop_patience, \n",
    "                 neurons, dropout, prd_range, batch_size, keras_tuner_dir, activ_func=\"sigmoid\", loss=\"binary_crossentropy\", \n",
    "                 optimizer=\"adam\"): # #activ_func=\"linear\", loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "                 \n",
    "    \n",
    "    def build_model(hp):\n",
    "        model = Sequential()\n",
    "        \n",
    "        \n",
    "        ###########1D CONV############\n",
    "        #filters_conv1 = hp.Choice('filters_Conv1', values=[16, 32, 64])\n",
    "        #kernel_size_conv1 = hp.Choice('kernel_size_Conv1', values=[2, 3, 5])\n",
    "        #strides_conv1 = hp.Choice('strides_Conv1', values=[1, 2, 3])\n",
    "        #model.add(Conv1D(filters=filters_conv1, kernel_size=kernel_size_conv1, strides=strides_conv1, \n",
    "        #                 activation='relu',\n",
    "        #                input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "       \n",
    "    \n",
    "        #############2D CONV##########\n",
    "        #filters_conv2 = hp.Choice('filters_Conv2', values=[16, 32, 64])\n",
    "        #kernel_size_conv2 = hp.Choice('kernel_size_Conv2', values=[2, 3, 5])\n",
    "        #strides_conv2 = hp.Choice('strides_Conv2', values=[(1, 1), (2, 2), (3, 3)])\n",
    "        #tf.keras.layers.Conv2D(filters=filters_conv2, kernel_size=kernel_size_conv2, strides=strides_conv2, \n",
    "        #                       activation='relu',\n",
    "        #                       input_shape=(1, inputs.shape[1], inputs.shape[2]), data_format=channels_first)\n",
    "        \n",
    "        \n",
    "        #moment_batchNormConv1 = hp.Float('momentum_batchNormConv1', min_value=0.09, max_value=0.99, step=0.1)\n",
    "        #model.add(BatchNormalization(momentum=moment_batchNormConv1))\n",
    "        \n",
    "        \n",
    "        ######1D POOL########\n",
    "        #pool_size_maxPool1 = hp.Choice('pool_size_MaxPool1', values=[2, 3, 4])\n",
    "        #model.add(MaxPool1D(pool_size=2))\n",
    "        #model.add(AveragePooling1D(pool_size=2))\n",
    "        \n",
    "        \n",
    "        #############2D POOL##########\n",
    "        #model.add(MaxPool2D(pool_size=(2, 2), data_format=channels_first)\n",
    "\n",
    "        neurGRU1 = hp.Choice('neurons_1_GRU', values=neurons) #neurLSTM1 = hp.Choice('neurons_1_LSTM', values=neurons)\n",
    "        model.add(GRU(neurGRU1, input_shape=(inputs.shape[1], inputs.shape[2])))#model.add(LSTM(neurLSTM1, input_shape=(inputs.shape[1], inputs.shape[2]))) #return_sequences=True\n",
    "\n",
    "        #dropGRU1 = hp.Choice('dropout_GRU_1', values=dropout)#dropLSTM1 = hp.Choice('dropout_LSTM_1', values=dropout)\n",
    "        #model.add(Dropout(dropGRU1))#model.add(Dropout(dropLSTM1))\n",
    "        \n",
    "        #neurGRU2 = hp.Choice('neurons_2_GRU', values=neurons)#neurLSTM2 = hp.Choice('neurons_2_LSTM', values=neurons)\n",
    "        #model.add(GRU(neurGRU2))#model.add(LSTM(neurLSTM2))\n",
    "        \n",
    "        #dropGRU2 = hp.Choice('dropout_GRU_2', values=dropout)#dropLSTM2 = hp.Choice('dropout_LSTM_2', values=dropout)\n",
    "        #model.add(Dropout(dropGRU2))#model.add(Dropout(dropLSTM2))\n",
    "        \n",
    "        \n",
    "        #moment_batchNormLSTM2 = hp.Float('momentum_batchNormLSTM2', min_value=0.09, max_value=0.99, step=0.1)\n",
    "        #model.add(BatchNormalization(momentum=moment_batchNormLSTM2))\n",
    "\n",
    "        neurD1 = hp.Choice('neurons_1_Dense', values=[32, 64, 128, 256])\n",
    "        model.add(Dense(units=neurD1, activation='relu'))\n",
    "        \n",
    "        dropDense1 = hp.Choice('dropout_Dense_1', values=dropout)\n",
    "        model.add(Dropout(dropDense1))\n",
    "        \n",
    "        #moment_batchNormDense1 = hp.Float('momentum_batchNormDense1', min_value=0.09, max_value=0.99, step=0.1)\n",
    "        #model.add(BatchNormalization(momentum=moment_batchNormDense1))\n",
    "        \n",
    "        neurD2 = hp.Choice('neurons_2_Dense', values=[32, 64, 128, 256])\n",
    "        model.add(Dense(units=neurD2, activation='relu'))\n",
    "        \n",
    "        dropDense2 = hp.Choice('dropout_Dense_2', values=dropout)\n",
    "        model.add(Dropout(dropDense2))\n",
    "        \n",
    "        #moment_batchNormDense2 = hp.Float('momentum_batchNormDense2', min_value=0.09, max_value=0.99, step=0.1)\n",
    "        #model.add(BatchNormalization(momentum=moment_batchNormDense2))\n",
    "        \n",
    "        model.add(Dense(units=output_size))\n",
    "        model.add(Activation(activ_func))\n",
    "        \n",
    "        #hp_learning_rate = hp.Float(name='learning_rate', min_value=0.0001, max_value=0.05, step=0.0005)\n",
    "        \n",
    "        #hp_beta_1 = hp.Float('beta_1', min_value=0.85, max_value=0.95, step=0.01)\n",
    "        \n",
    "        #hp_beta_2 = hp.Float('beta_2', min_value=0.98, max_value=0.999, step=0.001)\n",
    "        \n",
    "        #hp_epsilon = hp.Float('epsilon', min_value=1e-07, max_value=1e-08, sampling='LOG')\n",
    "        \n",
    "        #optimizer = tf.keras.optimizers.Adam(\n",
    "        #learning_rate=hp_learning_rate, beta_1=hp_beta_1, beta_2=hp_beta_2, epsilon=hp_epsilon)\n",
    "        \n",
    "        model.compile(loss=loss, optimizer=optimizer, \n",
    "                      metrics=[tfa.metrics.F1Score(average='macro', num_classes=output_size)])\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Create_tuner\n",
    "    tuner = kt.Hyperband(build_model,\n",
    "                 objective='val_loss',\n",
    "                 max_epochs=epochs,\n",
    "                 factor=3,\n",
    "                 directory=keras_tuner_dir,\n",
    "                 project_name='keras_tuner')\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stop_patience)\n",
    "\n",
    "    tuner.search(inputs[:-prd_range], outputs, \n",
    "                 validation_data=(validation_inputs[:-prd_range], validation_outputs), \n",
    "                 epochs=epochs, batch_size=batch_size,callbacks=[stop_early],\n",
    "                 use_multiprocessing=True,\n",
    "                 workers=8)\n",
    "\n",
    "    # Get the optimal hyperparameters\n",
    "    best_hps=tuner.get_best_hyperparameters(num_trials=3)[0]\n",
    "\n",
    "    \n",
    "    return best_hps, tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 20s]\n",
      "val_loss: 0.3191845715045929\n",
      "\n",
      "Best val_loss So Far: 0.28922080993652344\n",
      "Total elapsed time: 00h 35m 34s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 6s 84ms/step - loss: 0.6905 - f1_score: 0.3686 - val_loss: 0.5843 - val_f1_score: 0.4580\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.6898 - f1_score: 0.3855 - val_loss: 0.5662 - val_f1_score: 0.4580\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.6895 - f1_score: 0.3783 - val_loss: 0.4858 - val_f1_score: 0.4580\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.7015 - f1_score: 0.4674 - val_loss: 0.7946 - val_f1_score: 0.1342\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.6728 - f1_score: 0.5167 - val_loss: 0.5171 - val_f1_score: 0.4580\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.6581 - f1_score: 0.5337 - val_loss: 0.6100 - val_f1_score: 0.4580\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.6479 - f1_score: 0.5729 - val_loss: 0.6899 - val_f1_score: 0.5940\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.6319 - f1_score: 0.6313 - val_loss: 0.3908 - val_f1_score: 0.4580\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.6110 - f1_score: 0.6380 - val_loss: 0.4258 - val_f1_score: 0.5943\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.6121 - f1_score: 0.6301 - val_loss: 0.7417 - val_f1_score: 0.3823\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.5472 - f1_score: 0.7145 - val_loss: 0.3791 - val_f1_score: 0.5528\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.5728 - f1_score: 0.6875 - val_loss: 0.4285 - val_f1_score: 0.6914\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.4988 - f1_score: 0.7643 - val_loss: 0.6154 - val_f1_score: 0.5665\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.5363 - f1_score: 0.7075 - val_loss: 0.4810 - val_f1_score: 0.6828\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.5099 - f1_score: 0.7411 - val_loss: 0.4347 - val_f1_score: 0.6678\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.5163 - f1_score: 0.7018 - val_loss: 0.3640 - val_f1_score: 0.6698\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.5007 - f1_score: 0.7257 - val_loss: 0.9495 - val_f1_score: 0.3101\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 2s 57ms/step - loss: 0.5190 - f1_score: 0.7159 - val_loss: 0.3776 - val_f1_score: 0.6678\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.4702 - f1_score: 0.7489 - val_loss: 0.3754 - val_f1_score: 0.6795\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.4641 - f1_score: 0.7470 - val_loss: 0.4534 - val_f1_score: 0.7003\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.4618 - f1_score: 0.7591 - val_loss: 0.4251 - val_f1_score: 0.6687\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.4870 - f1_score: 0.7240 - val_loss: 0.8928 - val_f1_score: 0.3753\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.4937 - f1_score: 0.6901 - val_loss: 0.3504 - val_f1_score: 0.7095\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.4576 - f1_score: 0.7559 - val_loss: 0.4216 - val_f1_score: 0.6828\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 2s 57ms/step - loss: 0.4579 - f1_score: 0.7266 - val_loss: 0.3780 - val_f1_score: 0.6605\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.4585 - f1_score: 0.7317 - val_loss: 0.5310 - val_f1_score: 0.6082\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.4538 - f1_score: 0.7657 - val_loss: 0.3503 - val_f1_score: 0.6325\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.4530 - f1_score: 0.7347 - val_loss: 0.4412 - val_f1_score: 0.6825\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 0.4482 - f1_score: 0.7619 - val_loss: 0.4043 - val_f1_score: 0.6605\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.4491 - f1_score: 0.7543 - val_loss: 0.4302 - val_f1_score: 0.6905\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 0.4155 - f1_score: 0.7704 - val_loss: 0.3288 - val_f1_score: 0.6605\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.4405 - f1_score: 0.7601 - val_loss: 0.4217 - val_f1_score: 0.6791\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.4275 - f1_score: 0.7609 - val_loss: 0.6663 - val_f1_score: 0.5710\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.4553 - f1_score: 0.7488 - val_loss: 0.3707 - val_f1_score: 0.6884\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.4110 - f1_score: 0.7826 - val_loss: 0.3451 - val_f1_score: 0.5943\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.4305 - f1_score: 0.7654 - val_loss: 0.7291 - val_f1_score: 0.4812\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.4671 - f1_score: 0.7473 - val_loss: 0.4262 - val_f1_score: 0.5075\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.4728 - f1_score: 0.7326 - val_loss: 0.3371 - val_f1_score: 0.6605\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.3968 - f1_score: 0.8073 - val_loss: 0.3809 - val_f1_score: 0.6884\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.4154 - f1_score: 0.7828 - val_loss: 0.3382 - val_f1_score: 0.6605\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.3820 - f1_score: 0.7912 - val_loss: 0.3168 - val_f1_score: 0.6898\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3770 - f1_score: 0.7907 - val_loss: 0.3439 - val_f1_score: 0.6605\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.3670 - f1_score: 0.8131 - val_loss: 0.3114 - val_f1_score: 0.6698\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.4216 - f1_score: 0.7647 - val_loss: 0.3193 - val_f1_score: 0.7006\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3747 - f1_score: 0.8109 - val_loss: 0.3399 - val_f1_score: 0.6678\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 2s 57ms/step - loss: 0.3844 - f1_score: 0.7991 - val_loss: 0.3327 - val_f1_score: 0.6678\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.3907 - f1_score: 0.7982 - val_loss: 0.3583 - val_f1_score: 0.6517\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3702 - f1_score: 0.8112 - val_loss: 0.3344 - val_f1_score: 0.7006\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.3574 - f1_score: 0.8142 - val_loss: 0.3432 - val_f1_score: 0.6789\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.3670 - f1_score: 0.8150 - val_loss: 0.3449 - val_f1_score: 0.6678\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.3756 - f1_score: 0.7969 - val_loss: 0.3692 - val_f1_score: 0.5943\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.4146 - f1_score: 0.7766 - val_loss: 0.3582 - val_f1_score: 0.6224\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.3661 - f1_score: 0.7923 - val_loss: 0.3247 - val_f1_score: 0.6612\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3319 - f1_score: 0.8299 - val_loss: 0.4641 - val_f1_score: 0.6325\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.3422 - f1_score: 0.8199 - val_loss: 0.4043 - val_f1_score: 0.6794\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.4070 - f1_score: 0.7864 - val_loss: 0.3586 - val_f1_score: 0.6605\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.3518 - f1_score: 0.8233 - val_loss: 0.3276 - val_f1_score: 0.6698\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.3227 - f1_score: 0.8338 - val_loss: 0.3192 - val_f1_score: 0.6795\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.3102 - f1_score: 0.8322 - val_loss: 0.3071 - val_f1_score: 0.6898\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3403 - f1_score: 0.8163 - val_loss: 0.3165 - val_f1_score: 0.6605\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.3109 - f1_score: 0.8267 - val_loss: 0.4490 - val_f1_score: 0.6325\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.3234 - f1_score: 0.8192 - val_loss: 0.3016 - val_f1_score: 0.6789\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.3635 - f1_score: 0.8216 - val_loss: 0.3685 - val_f1_score: 0.6325\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3346 - f1_score: 0.8246 - val_loss: 0.4811 - val_f1_score: 0.5528\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3563 - f1_score: 0.8199 - val_loss: 0.3565 - val_f1_score: 0.6795\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3158 - f1_score: 0.8410 - val_loss: 0.3898 - val_f1_score: 0.6678\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3379 - f1_score: 0.8217 - val_loss: 0.3557 - val_f1_score: 0.7006\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3228 - f1_score: 0.8313 - val_loss: 0.4331 - val_f1_score: 0.6678\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.3166 - f1_score: 0.8381 - val_loss: 0.3073 - val_f1_score: 0.6789\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.2944 - f1_score: 0.8564 - val_loss: 0.3099 - val_f1_score: 0.6605\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3045 - f1_score: 0.8497 - val_loss: 0.3600 - val_f1_score: 0.7090\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.3038 - f1_score: 0.8391 - val_loss: 0.3192 - val_f1_score: 0.6884\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.3231 - f1_score: 0.8357 - val_loss: 0.3446 - val_f1_score: 0.7006\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.2924 - f1_score: 0.8520 - val_loss: 0.6078 - val_f1_score: 0.5528\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.2917 - f1_score: 0.8542 - val_loss: 0.3108 - val_f1_score: 0.6605\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.3150 - f1_score: 0.8543 - val_loss: 0.3119 - val_f1_score: 0.6884\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.2978 - f1_score: 0.8404 - val_loss: 0.3092 - val_f1_score: 0.6898\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.2749 - f1_score: 0.8722 - val_loss: 0.3188 - val_f1_score: 0.6605\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.2991 - f1_score: 0.8565 - val_loss: 0.3552 - val_f1_score: 0.6789\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.2817 - f1_score: 0.8698 - val_loss: 0.3152 - val_f1_score: 0.7006\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.2934 - f1_score: 0.8557 - val_loss: 0.3311 - val_f1_score: 0.6898\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.2884 - f1_score: 0.8587 - val_loss: 0.3136 - val_f1_score: 0.6898\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 0.2673 - f1_score: 0.8642 - val_loss: 0.3917 - val_f1_score: 0.7006\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 0.2590 - f1_score: 0.8855 - val_loss: 0.3197 - val_f1_score: 0.6884\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.2879 - f1_score: 0.8553 - val_loss: 0.3356 - val_f1_score: 0.6898\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 2s 57ms/step - loss: 0.2319 - f1_score: 0.8914 - val_loss: 0.4813 - val_f1_score: 0.6325\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: 0.2738 - f1_score: 0.8717 - val_loss: 0.3371 - val_f1_score: 0.6678\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.2872 - f1_score: 0.8645 - val_loss: 0.3642 - val_f1_score: 0.7006\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.2841 - f1_score: 0.8563 - val_loss: 0.3425 - val_f1_score: 0.6789\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.2650 - f1_score: 0.8710 - val_loss: 0.3613 - val_f1_score: 0.6678\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.2564 - f1_score: 0.8786 - val_loss: 0.3636 - val_f1_score: 0.7006\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.2509 - f1_score: 0.8753 - val_loss: 0.4447 - val_f1_score: 0.7006\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.2890 - f1_score: 0.8559 - val_loss: 0.4120 - val_f1_score: 0.6721\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.2719 - f1_score: 0.8753 - val_loss: 0.5155 - val_f1_score: 0.5943\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.2451 - f1_score: 0.8679 - val_loss: 0.3262 - val_f1_score: 0.6898\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.2333 - f1_score: 0.8858 - val_loss: 0.3147 - val_f1_score: 0.6789\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.2409 - f1_score: 0.8942 - val_loss: 0.4636 - val_f1_score: 0.6678\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.2802 - f1_score: 0.8645 - val_loss: 0.3465 - val_f1_score: 0.6678\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 2s 58ms/step - loss: 0.2469 - f1_score: 0.8877 - val_loss: 0.3892 - val_f1_score: 0.6578\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 2s 57ms/step - loss: 0.2741 - f1_score: 0.8568 - val_loss: 0.5746 - val_f1_score: 0.5528\n"
     ]
    }
   ],
   "source": [
    "#Get data\n",
    "crypto_list = [['BTC-USD', 'ETH-USD', 'DOGE-USD', 'USDT-USD']] #, 'DOGE-USD', 'USDT-USD','XRP-USD', 'LTC-USD', 'XLM-USD', \n",
    "                #'XMR-USD', 'BNB-USD', 'ADA-USD', 'BCH-USD', 'LINK-USD', 'ETC-USD', 'EOS-USD', 'TRX-USD',\n",
    "               #'FIL-USD', 'NEO-USD', 'XTZ-USD', 'MIOTA-USD']] #Define the sets of cryptocurrencies to be tested\n",
    "\n",
    "\n",
    "social_usage_flag = False        \n",
    "first_txt_flag = 0\n",
    "\n",
    "\n",
    "for cryptocurrency_list in crypto_list:\n",
    "    \n",
    "    cryptocurrency_list_output = 'Using cryptocurrencies: '+str(cryptocurrency_list)\n",
    "    print(cryptocurrency_list_output)\n",
    "    data = dataset_creation(cryptocurrency_list, path, social_path, social_usage_flag)\n",
    "    \n",
    "    #Split data\n",
    "    percent_train_set = 0.8\n",
    "    percent_val_set = 0.5\n",
    "\n",
    "    training_set, validation_set, test_set, split_date_train, split_date_valid = split_data(percent_train_set, \n",
    "                                                                                           percent_val_set, data)\n",
    "\n",
    "    \n",
    "    features_list = [['Close']]\n",
    "    \"\"\",'comments', 'fb_likes', 'fb_talking_about', 'twitter_followers', 'reddit_comments_per_day', 'code_repo_stars', 'code_repo_open_issues'\"\"\"\n",
    "    \"\"\"[['Close'], ['Close', 'Market_Cap', 'Volume'], ['Close', 'Open', 'High'],\n",
    "                     ['Close', 'close_off_high', 'volatility'],\n",
    "                     ['Close', 'mean_7days_Close', 'mean_month_Close'],\n",
    "                     ['Close', 'std_7days_Close', 'std_month_Close']]\"\"\" #Define the sets of features to be tested \n",
    "    \n",
    "    for featurs in features_list: \n",
    "        \n",
    "        new_txt_flag = 0 \n",
    "        \n",
    "        featurs_output = '\\tUsing the features: '+str(featurs)\n",
    "        print('\\tUsing the features: '+str(featurs))\n",
    "        \n",
    "        \n",
    "        #Create inputs and outputs for the model training, validation and testing\n",
    "        pred_range = 1\n",
    "        window_len = 10\n",
    "        features = featurs\n",
    "        coin_target = 'BTC-USD'\n",
    "        \n",
    "        \n",
    "\n",
    "        LSTM_ranged_training_outputs, LSTM_ranged_validation_outputs, LSTM_rangd_test_outputs, LSTM_training_inputs, LSTM_validation_inputs, LSTM_test_inputs = normalize_in_out(\n",
    "                                                                                                      pred_range, window_len, \n",
    "                                                                                                      training_set, \n",
    "                                                                                                      validation_set, \n",
    "                                                                                                      test_set, \n",
    "                                                                                                      features, coin_target,\n",
    "                                                                                                      cryptocurrency_list)\n",
    "        \n",
    "        \n",
    "        #Uncomment if you want to build and train a model without tuning. Comment all the below.\n",
    "        \"\"\"rnged_btcoin_model, rnged_hist = build_and_train_model(LSTM_training_inputs, LSTM_ranged_training_outputs, \n",
    "                                                               pred_range*2, LSTM_validation_inputs,\n",
    "                                                               LSTM_ranged_validation_outputs, neurons=20, \n",
    "                                                               prd_range=pred_range, epochs=500, batch_size=32)\"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        batch_size_list = [64] #[1, 32, 64]\n",
    "        neuron_list = [20, 40, 60, 100, 128, 256, 512]\n",
    "        dropout_list = [0.0, 0.1, 0.2, 0.25, 0.3, 0.4]\n",
    "        early_stop_patience = 10\n",
    "        epochs = 100\n",
    "        shuffle = True\n",
    "        verbose = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for bat_s in batch_size_list:\n",
    "\n",
    "            #Build and train model\n",
    "            batch_size = bat_s\n",
    "            \n",
    "            \n",
    "            exper_params_output = '\\t\\tBatch_size: '+str(batch_size)\n",
    "            print(exper_params_output)\n",
    "           \n",
    "            \n",
    "            #Path to write log files\n",
    "            cur_path = os.getcwd()+'/'\n",
    "            log_dir = cur_path + \"logs/fit/\" + str(cryptocurrency_list) + '/' + str(featurs) + '/' + 'Batch_size='+str(batch_size)\n",
    "            if not os.path.exists(log_dir):\n",
    "                os.makedirs(log_dir)\n",
    "            \n",
    "            #Path to save its checkpoints the keras_tuner because it raises an error when it is in the current working\n",
    "            #directory or in a sub-folder\n",
    "            keras_tuner_dir = 'C:\\keras_tuner'\n",
    "            if not os.path.exists(keras_tuner_dir):\n",
    "                os.makedirs(keras_tuner_dir)\n",
    "            \n",
    "            best_hps, tuner = model_tuning(inputs=LSTM_training_inputs, outputs=LSTM_ranged_training_outputs,\n",
    "                                output_size=pred_range*2, \n",
    "                                validation_inputs = LSTM_validation_inputs, \n",
    "                                validation_outputs = LSTM_ranged_validation_outputs,\n",
    "                                epochs=epochs, early_stop_patience=early_stop_patience, neurons=neuron_list, \n",
    "                                dropout=dropout_list, prd_range=pred_range, batch_size=bat_s, \n",
    "                                           keras_tuner_dir=keras_tuner_dir)\n",
    "        \n",
    "            exper_outputs = \"\\t\\tThe hyperparameter search is complete. The optimal parameter were found to be: \\n\" + \\\n",
    "                            str(tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values)\n",
    "        \n",
    "            \n",
    "            \n",
    "            # Build the model with the optimal hyperparameters and train it\n",
    "            best_model = tuner.hypermodel.build(best_hps)\n",
    "            mod_history = best_model.fit(LSTM_training_inputs[:-pred_range], \n",
    "                                         LSTM_ranged_training_outputs, \n",
    "                                         validation_data=(LSTM_validation_inputs[:-pred_range], \n",
    "                                                          LSTM_ranged_validation_outputs), \n",
    "                                         epochs=epochs)\n",
    "            \n",
    "            \n",
    "            #Get the epoch with the best validation loss\n",
    "            val_loss_per_epoch = mod_history.history['val_loss']\n",
    "            val_f1_score_per_epoch = mod_history.history['val_f1_score']\n",
    "            best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "            exper_outputs += '\\n\\n\\t\\tBest epoch: '+ str(best_epoch) + ' with validation loss: ' + str((min(val_loss_per_epoch))) + ' and F1 macro: ' + str(val_f1_score_per_epoch[best_epoch])\n",
    "            \n",
    "            #Print results to a .txt file\n",
    "            if first_txt_flag == 0:\n",
    "                \n",
    "                if new_txt_flag == 0:\n",
    "                    \n",
    "                    #Create a .txt file and write the results\n",
    "                    txt_log_dir = \"logs/fit/\" + str(cryptocurrency_list) + '/' + str(featurs) + '/'\n",
    "                    f = open(txt_log_dir+\"/\"+coin_target+\"_results.txt\", \"w\")\n",
    "                    f.write(cryptocurrency_list_output)\n",
    "                    f.write(\"\\n\"+featurs_output)\n",
    "                    \n",
    "                    first_txt_flag += 1\n",
    "                    new_txt_flag += 1\n",
    "            else:\n",
    "                \n",
    "                if new_txt_flag == 0:\n",
    "                    \n",
    "                    f.close() #Close previous txt file\n",
    "                    \n",
    "                    #Create a .txt file and write the results\n",
    "                    txt_log_dir = \"logs/fit/\" + str(cryptocurrency_list) + '/' + str(featurs) + '/'\n",
    "                    f = open(txt_log_dir+\"/\"+coin_target+\"_results.txt\", \"w\")\n",
    "                    f.write(cryptocurrency_list_output)\n",
    "                    f.write(\"\\n\"+featurs_output)\n",
    "                    \n",
    "                    new_txt_flag += 1\n",
    "                    \n",
    "                \n",
    "            \n",
    "            f.write(\"\\n\"+exper_params_output)\n",
    "            f.write(\"\\n\"+exper_outputs)\n",
    "            \n",
    "            f.write(\"\\n\\nFull keras tuner results: \\n\")\n",
    "            with redirect_stdout(f): \n",
    "                tuner.results_summary()\n",
    "            \n",
    "            \n",
    "            create_plot(mod_history, log_dir, coin_target)\n",
    "            create_F1_macro_plot(mod_history, log_dir, coin_target)\n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "#Write best model summary to a txt file\n",
    "with open(cur_path + 'logs/fit/modelsummary.txt', 'w') as f_sum:\n",
    "    with redirect_stdout(f_sum):\n",
    "        best_model.summary()\n",
    "        \n",
    "\n",
    "#Remove folder with is created by keras tuner\n",
    "shutil.rmtree(keras_tuner_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cryptocurrencies: ['ADA-USD']\n",
      "\tUsing the features: ['Close']\n",
      "Epoch 1/500\n",
      "17/17 - 9s - loss: 0.6945 - f1_score: 0.3707 - val_loss: 0.7067 - val_f1_score: 0.1678\n",
      "Epoch 2/500\n",
      "17/17 - 0s - loss: 0.6930 - f1_score: 0.3447 - val_loss: 0.7015 - val_f1_score: 0.1678\n",
      "Epoch 3/500\n",
      "17/17 - 0s - loss: 0.6939 - f1_score: 0.3642 - val_loss: 0.7040 - val_f1_score: 0.1678\n",
      "Epoch 4/500\n",
      "17/17 - 0s - loss: 0.6929 - f1_score: 0.4520 - val_loss: 0.6856 - val_f1_score: 0.4387\n",
      "Epoch 5/500\n",
      "17/17 - 0s - loss: 0.6936 - f1_score: 0.4801 - val_loss: 0.6966 - val_f1_score: 0.1678\n",
      "Epoch 6/500\n",
      "17/17 - 0s - loss: 0.6935 - f1_score: 0.4245 - val_loss: 0.6765 - val_f1_score: 0.4439\n",
      "Epoch 7/500\n",
      "17/17 - 0s - loss: 0.6914 - f1_score: 0.5218 - val_loss: 0.7071 - val_f1_score: 0.1678\n",
      "Epoch 8/500\n",
      "17/17 - 0s - loss: 0.6911 - f1_score: 0.4933 - val_loss: 0.7127 - val_f1_score: 0.1678\n",
      "Epoch 9/500\n",
      "17/17 - 0s - loss: 0.6889 - f1_score: 0.5372 - val_loss: 0.7293 - val_f1_score: 0.1678\n",
      "Epoch 10/500\n",
      "17/17 - 0s - loss: 0.6871 - f1_score: 0.5279 - val_loss: 0.6618 - val_f1_score: 0.4413\n",
      "Epoch 11/500\n",
      "17/17 - 0s - loss: 0.6886 - f1_score: 0.5112 - val_loss: 0.7880 - val_f1_score: 0.1678\n",
      "Epoch 12/500\n",
      "17/17 - 0s - loss: 0.6828 - f1_score: 0.5496 - val_loss: 0.7287 - val_f1_score: 0.1794\n",
      "Epoch 13/500\n",
      "17/17 - 0s - loss: 0.6688 - f1_score: 0.5984 - val_loss: 0.6886 - val_f1_score: 0.3848\n",
      "Epoch 14/500\n",
      "17/17 - 0s - loss: 0.6616 - f1_score: 0.5827 - val_loss: 1.0112 - val_f1_score: 0.1678\n",
      "Epoch 15/500\n",
      "17/17 - 0s - loss: 0.6669 - f1_score: 0.5769 - val_loss: 0.7840 - val_f1_score: 0.2131\n",
      "Epoch 16/500\n",
      "17/17 - 0s - loss: 0.6546 - f1_score: 0.5798 - val_loss: 0.8290 - val_f1_score: 0.2131\n",
      "Epoch 17/500\n",
      "17/17 - 0s - loss: 0.6504 - f1_score: 0.5703 - val_loss: 0.8934 - val_f1_score: 0.1908\n",
      "Epoch 18/500\n",
      "17/17 - 0s - loss: 0.6589 - f1_score: 0.5760 - val_loss: 0.6867 - val_f1_score: 0.5082\n",
      "Epoch 19/500\n",
      "17/17 - 0s - loss: 0.6402 - f1_score: 0.6133 - val_loss: 0.7366 - val_f1_score: 0.3513\n",
      "Epoch 20/500\n",
      "17/17 - 0s - loss: 0.6393 - f1_score: 0.6322 - val_loss: 0.7796 - val_f1_score: 0.2954\n"
     ]
    }
   ],
   "source": [
    "#Get data\n",
    "crypto_list = [['ADA-USD']] #, 'DOGE-USD', 'USDT-USD','XRP-USD', 'LTC-USD', 'XLM-USD', \n",
    "                #'XMR-USD', 'BNB-USD', 'ADA-USD', 'BCH-USD', 'LINK-USD', 'ETC-USD', 'EOS-USD', 'TRX-USD',\n",
    "               #'FIL-USD', 'NEO-USD', 'XTZ-USD', 'MIOTA-USD']] #Define the sets of cryptocurrencies to be tested\n",
    "\n",
    "social_usage_flag = False\n",
    "first_txt_flag = 0\n",
    "\n",
    "\n",
    "for cryptocurrency_list in crypto_list:\n",
    "    \n",
    "    cryptocurrency_list_output = 'Using cryptocurrencies: '+str(cryptocurrency_list)\n",
    "    print(cryptocurrency_list_output)\n",
    "    data = dataset_creation(cryptocurrency_list, path, social_path, social_usage_flag)\n",
    "    \n",
    "    #Split data\n",
    "    percent_train_set = 0.8\n",
    "    percent_val_set = 0.5\n",
    "\n",
    "    training_set, validation_set, test_set, split_date_train, split_date_valid = split_data(percent_train_set, \n",
    "                                                                                           percent_val_set, data)\n",
    "\n",
    "    \n",
    "    features_list = [['Close']]\n",
    "    \"\"\",'comments', 'fb_likes', 'fb_talking_about', 'twitter_followers', 'reddit_comments_per_day', 'code_repo_stars', 'code_repo_open_issues'\"\"\"\n",
    "    \"\"\"[['Close'], ['Close', 'Market_Cap', 'Volume'], ['Close', 'Open', 'High'],\n",
    "                     ['Close', 'close_off_high', 'volatility'],\n",
    "                     ['Close', 'mean_7days_Close', 'mean_month_Close'],\n",
    "                     ['Close', 'std_7days_Close', 'std_month_Close']]\"\"\" #Define the sets of features to be tested \n",
    "    \n",
    "    for featurs in features_list: \n",
    "        \n",
    "        new_txt_flag = 0 \n",
    "        \n",
    "        featurs_output = '\\tUsing the features: '+str(featurs)\n",
    "        print('\\tUsing the features: '+str(featurs))\n",
    "        \n",
    "        \n",
    "        #Create inputs and outputs for the model training, validation and testing\n",
    "        pred_range = 1\n",
    "        window_len = 10\n",
    "        features = featurs\n",
    "        coin_target = 'ADA-USD'\n",
    "        \n",
    "        \n",
    "\n",
    "        LSTM_ranged_training_outputs, LSTM_ranged_validation_outputs, LSTM_rangd_test_outputs, LSTM_training_inputs, LSTM_validation_inputs, LSTM_test_inputs = normalize_in_out(\n",
    "                                                                                                      pred_range, window_len, \n",
    "                                                                                                      training_set, \n",
    "                                                                                                      validation_set, \n",
    "                                                                                                      test_set, \n",
    "                                                                                                      features, coin_target,\n",
    "                                                                                                      cryptocurrency_list)\n",
    "            \n",
    "        rnged_btcoin_model, rnged_hist = build_and_train_model(LSTM_training_inputs, LSTM_ranged_training_outputs, \n",
    "                                                               pred_range*2, LSTM_validation_inputs,\n",
    "                                                               LSTM_ranged_validation_outputs, GRU_neurons=20, \n",
    "                                                               first_dense_neurons=256, first_dropout=0.4, \n",
    "                                                               second_dense_neurons=128, second_dropout=0.25, \n",
    "                                                               prd_range=pred_range, epochs=500, batch_size=64,\n",
    "                                                               early_stop_patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = r'C:\\Users\\georg\\Documents\\mine\\εργασιες\\μεταπτυχιακό\\2ο εξάμηνο\\Βαθιά Μηχανική Μάθηση\\Γιαννακόπουλος\\temp'\n",
    "create_plot(rnged_hist, log_dir, coin_target)\n",
    "create_F1_macro_plot(rnged_hist, log_dir, coin_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29535563958050937\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_coin = 'ADA'\n",
    "pretrained_model_coin = 'ADA'\n",
    "preds = rnged_btcoin_model.predict(LSTM_validation_inputs[:-pred_range])\n",
    "\n",
    "print(f1_score(LSTM_ranged_validation_outputs, np.round(preds), average='macro'))\n",
    "\n",
    "create_conf_matrix(preds, LSTM_ranged_validation_outputs, target_coin, pretrained_model_coin, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "#log_dir = r'C:\\Users\\georg\\Documents\\mine\\εργασιες\\μεταπτυχιακό\\2ο εξάμηνο\\Βαθιά Μηχανική Μάθηση\\Γιαννακόπουλος\\temp'\n",
    "#rnged_btcoin_model.save_weights(log_dir+'/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save BTC trained model\n",
    "#btcoin_model = rnged_btcoin_model\n",
    "#eth_btcoin_model = rnged_btcoin_model\n",
    "#usdt_doge_eth_btcoin_model = rnged_btcoin_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction of different coin than this that the model was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = btcoin_model.predict(LSTM_validation_inputs[:-pred_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4439252336448598"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(LSTM_ranged_validation_outputs, np.round(preds), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_coin = 'ADA'\n",
    "pretrained_model_coin = 'BTC'\n",
    "\n",
    "create_conf_matrix(preds, LSTM_ranged_validation_outputs, target_coin, pretrained_model_coin, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to train a little bit the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 - 9s - loss: 0.6943 - f1_score: 0.3990 - val_loss: 0.7091 - val_f1_score: 0.1678\n",
      "Epoch 2/500\n",
      "17/17 - 0s - loss: 0.6929 - f1_score: 0.3409 - val_loss: 0.7155 - val_f1_score: 0.1678\n",
      "Epoch 3/500\n",
      "17/17 - 0s - loss: 0.6936 - f1_score: 0.3370 - val_loss: 0.7075 - val_f1_score: 0.1678\n",
      "Epoch 4/500\n",
      "17/17 - 0s - loss: 0.6943 - f1_score: 0.4464 - val_loss: 0.6926 - val_f1_score: 0.4296\n",
      "Epoch 5/500\n",
      "17/17 - 0s - loss: 0.6929 - f1_score: 0.4390 - val_loss: 0.7076 - val_f1_score: 0.1678\n",
      "Epoch 6/500\n",
      "17/17 - 0s - loss: 0.6937 - f1_score: 0.4775 - val_loss: 0.7033 - val_f1_score: 0.1678\n",
      "Epoch 7/500\n",
      "17/17 - 0s - loss: 0.6921 - f1_score: 0.5242 - val_loss: 0.7205 - val_f1_score: 0.1678\n",
      "Epoch 8/500\n",
      "17/17 - 0s - loss: 0.6928 - f1_score: 0.3722 - val_loss: 0.7044 - val_f1_score: 0.2176\n",
      "Epoch 9/500\n",
      "17/17 - 0s - loss: 0.6933 - f1_score: 0.4521 - val_loss: 0.7042 - val_f1_score: 0.1678\n",
      "Epoch 10/500\n",
      "17/17 - 0s - loss: 0.6897 - f1_score: 0.4160 - val_loss: 0.7095 - val_f1_score: 0.1678\n",
      "Epoch 11/500\n",
      "17/17 - 0s - loss: 0.6900 - f1_score: 0.5491 - val_loss: 0.6794 - val_f1_score: 0.4778\n",
      "Epoch 12/500\n",
      "17/17 - 0s - loss: 0.6848 - f1_score: 0.5328 - val_loss: 0.7250 - val_f1_score: 0.1794\n",
      "Epoch 13/500\n",
      "17/17 - 0s - loss: 0.6813 - f1_score: 0.5343 - val_loss: 0.7838 - val_f1_score: 0.1678\n",
      "Epoch 14/500\n",
      "17/17 - 0s - loss: 0.6728 - f1_score: 0.5514 - val_loss: 0.6898 - val_f1_score: 0.5167\n",
      "Epoch 15/500\n",
      "17/17 - 0s - loss: 0.6751 - f1_score: 0.5637 - val_loss: 0.6214 - val_f1_score: 0.4860\n",
      "Epoch 16/500\n",
      "17/17 - 0s - loss: 0.6723 - f1_score: 0.5797 - val_loss: 0.7549 - val_f1_score: 0.2451\n",
      "Epoch 17/500\n",
      "17/17 - 0s - loss: 0.6543 - f1_score: 0.5900 - val_loss: 0.8090 - val_f1_score: 0.2131\n",
      "Epoch 18/500\n",
      "17/17 - 0s - loss: 0.6471 - f1_score: 0.5802 - val_loss: 0.7942 - val_f1_score: 0.2656\n",
      "Epoch 19/500\n",
      "17/17 - 0s - loss: 0.6375 - f1_score: 0.6275 - val_loss: 0.5834 - val_f1_score: 0.4853\n",
      "Epoch 20/500\n",
      "17/17 - 0s - loss: 0.6354 - f1_score: 0.6313 - val_loss: 0.8681 - val_f1_score: 0.2656\n",
      "Epoch 21/500\n",
      "17/17 - 0s - loss: 0.6457 - f1_score: 0.5855 - val_loss: 0.6138 - val_f1_score: 0.6177\n",
      "Epoch 22/500\n",
      "17/17 - 0s - loss: 0.6541 - f1_score: 0.6227 - val_loss: 0.6466 - val_f1_score: 0.6448\n",
      "Epoch 23/500\n",
      "17/17 - 0s - loss: 0.6220 - f1_score: 0.6497 - val_loss: 0.6809 - val_f1_score: 0.5561\n",
      "Epoch 24/500\n",
      "17/17 - 0s - loss: 0.6208 - f1_score: 0.6441 - val_loss: 0.6773 - val_f1_score: 0.5047\n",
      "Epoch 25/500\n",
      "17/17 - 0s - loss: 0.6182 - f1_score: 0.6370 - val_loss: 0.7188 - val_f1_score: 0.4200\n",
      "Epoch 26/500\n",
      "17/17 - 0s - loss: 0.6140 - f1_score: 0.6391 - val_loss: 0.6608 - val_f1_score: 0.5563\n",
      "Epoch 27/500\n",
      "17/17 - 0s - loss: 0.6063 - f1_score: 0.6658 - val_loss: 0.7778 - val_f1_score: 0.3778\n",
      "Epoch 28/500\n",
      "17/17 - 0s - loss: 0.6442 - f1_score: 0.5938 - val_loss: 0.7938 - val_f1_score: 0.3690\n",
      "Epoch 29/500\n",
      "17/17 - 0s - loss: 0.6356 - f1_score: 0.6445 - val_loss: 0.6517 - val_f1_score: 0.5196\n",
      "Epoch 30/500\n",
      "17/17 - 0s - loss: 0.6144 - f1_score: 0.6515 - val_loss: 0.5745 - val_f1_score: 0.7024\n",
      "Epoch 31/500\n",
      "17/17 - 0s - loss: 0.6067 - f1_score: 0.6797 - val_loss: 0.6444 - val_f1_score: 0.5925\n",
      "Epoch 32/500\n",
      "17/17 - 0s - loss: 0.5987 - f1_score: 0.6760 - val_loss: 0.5649 - val_f1_score: 0.6946\n",
      "Epoch 33/500\n",
      "17/17 - 0s - loss: 0.6132 - f1_score: 0.6503 - val_loss: 0.6835 - val_f1_score: 0.5143\n",
      "Epoch 34/500\n",
      "17/17 - 0s - loss: 0.6144 - f1_score: 0.6314 - val_loss: 0.5705 - val_f1_score: 0.6794\n",
      "Epoch 35/500\n",
      "17/17 - 0s - loss: 0.5875 - f1_score: 0.7051 - val_loss: 0.5861 - val_f1_score: 0.6615\n",
      "Epoch 36/500\n",
      "17/17 - 0s - loss: 0.5997 - f1_score: 0.6708 - val_loss: 0.4668 - val_f1_score: 0.4584\n",
      "Epoch 37/500\n",
      "17/17 - 0s - loss: 0.6270 - f1_score: 0.6425 - val_loss: 0.4648 - val_f1_score: 0.4584\n",
      "Epoch 38/500\n",
      "17/17 - 0s - loss: 0.6000 - f1_score: 0.6508 - val_loss: 0.5132 - val_f1_score: 0.5433\n",
      "Epoch 39/500\n",
      "17/17 - 0s - loss: 0.6034 - f1_score: 0.6770 - val_loss: 0.5624 - val_f1_score: 0.6480\n",
      "Epoch 40/500\n",
      "17/17 - 0s - loss: 0.5810 - f1_score: 0.6974 - val_loss: 0.5892 - val_f1_score: 0.6177\n",
      "Epoch 41/500\n",
      "17/17 - 0s - loss: 0.5850 - f1_score: 0.6944 - val_loss: 0.5760 - val_f1_score: 0.6593\n",
      "Epoch 42/500\n",
      "17/17 - 0s - loss: 0.5819 - f1_score: 0.6964 - val_loss: 0.5469 - val_f1_score: 0.6912\n",
      "Epoch 43/500\n",
      "17/17 - 0s - loss: 0.6015 - f1_score: 0.6634 - val_loss: 0.5445 - val_f1_score: 0.7008\n",
      "Epoch 44/500\n",
      "17/17 - 0s - loss: 0.5738 - f1_score: 0.6983 - val_loss: 0.5080 - val_f1_score: 0.7126\n",
      "Epoch 45/500\n",
      "17/17 - 0s - loss: 0.6195 - f1_score: 0.6997 - val_loss: 0.4741 - val_f1_score: 0.4808\n",
      "Epoch 46/500\n",
      "17/17 - 0s - loss: 0.5808 - f1_score: 0.6962 - val_loss: 0.4762 - val_f1_score: 0.5793\n",
      "Epoch 47/500\n",
      "17/17 - 0s - loss: 0.5786 - f1_score: 0.6856 - val_loss: 0.5525 - val_f1_score: 0.6946\n",
      "Epoch 48/500\n",
      "17/17 - 0s - loss: 0.5882 - f1_score: 0.6623 - val_loss: 0.6534 - val_f1_score: 0.5676\n",
      "Epoch 49/500\n",
      "17/17 - 0s - loss: 0.5843 - f1_score: 0.6633 - val_loss: 0.5603 - val_f1_score: 0.6615\n",
      "Epoch 50/500\n",
      "17/17 - 0s - loss: 0.5689 - f1_score: 0.7319 - val_loss: 0.6086 - val_f1_score: 0.6377\n",
      "Epoch 51/500\n",
      "17/17 - 0s - loss: 0.5837 - f1_score: 0.7283 - val_loss: 0.5033 - val_f1_score: 0.6607\n",
      "Epoch 52/500\n",
      "17/17 - 0s - loss: 0.5734 - f1_score: 0.7178 - val_loss: 0.5698 - val_f1_score: 0.6593\n",
      "Epoch 53/500\n",
      "17/17 - 0s - loss: 0.6070 - f1_score: 0.6759 - val_loss: 0.5197 - val_f1_score: 0.7165\n",
      "Epoch 54/500\n",
      "17/17 - 0s - loss: 0.5739 - f1_score: 0.6974 - val_loss: 0.5357 - val_f1_score: 0.7008\n",
      "Epoch 55/500\n",
      "17/17 - 0s - loss: 0.5679 - f1_score: 0.7049 - val_loss: 0.6713 - val_f1_score: 0.5997\n",
      "Epoch 56/500\n",
      "17/17 - 0s - loss: 0.5800 - f1_score: 0.6846 - val_loss: 0.5127 - val_f1_score: 0.6709\n",
      "Epoch 57/500\n",
      "17/17 - 0s - loss: 0.5902 - f1_score: 0.6605 - val_loss: 0.4947 - val_f1_score: 0.6607\n",
      "Epoch 58/500\n",
      "17/17 - 0s - loss: 0.5581 - f1_score: 0.7212 - val_loss: 0.5854 - val_f1_score: 0.6470\n",
      "Epoch 59/500\n",
      "17/17 - 0s - loss: 0.5722 - f1_score: 0.7218 - val_loss: 0.5087 - val_f1_score: 0.6531\n",
      "Epoch 60/500\n",
      "17/17 - 0s - loss: 0.5742 - f1_score: 0.6925 - val_loss: 0.4759 - val_f1_score: 0.6026\n",
      "Epoch 61/500\n",
      "17/17 - 0s - loss: 0.5973 - f1_score: 0.6719 - val_loss: 0.4866 - val_f1_score: 0.6607\n",
      "Epoch 62/500\n",
      "17/17 - 0s - loss: 0.5761 - f1_score: 0.6974 - val_loss: 0.5908 - val_f1_score: 0.6416\n",
      "Epoch 63/500\n",
      "17/17 - 0s - loss: 0.5800 - f1_score: 0.6962 - val_loss: 0.5534 - val_f1_score: 0.6688\n",
      "Epoch 64/500\n",
      "17/17 - 0s - loss: 0.5793 - f1_score: 0.6845 - val_loss: 0.5684 - val_f1_score: 0.6422\n",
      "Epoch 65/500\n",
      "17/17 - 0s - loss: 0.5750 - f1_score: 0.6786 - val_loss: 0.5360 - val_f1_score: 0.6931\n",
      "Epoch 66/500\n",
      "17/17 - 0s - loss: 0.5663 - f1_score: 0.7274 - val_loss: 0.5879 - val_f1_score: 0.6560\n",
      "Epoch 67/500\n",
      "17/17 - 0s - loss: 0.5810 - f1_score: 0.6760 - val_loss: 0.4512 - val_f1_score: 0.5952\n",
      "Epoch 68/500\n",
      "17/17 - 0s - loss: 0.5782 - f1_score: 0.6922 - val_loss: 0.5301 - val_f1_score: 0.7103\n",
      "Epoch 69/500\n",
      "17/17 - 0s - loss: 0.5555 - f1_score: 0.7157 - val_loss: 0.6323 - val_f1_score: 0.5782\n",
      "Epoch 70/500\n",
      "17/17 - 0s - loss: 0.5665 - f1_score: 0.7066 - val_loss: 0.5745 - val_f1_score: 0.6234\n",
      "Epoch 71/500\n",
      "17/17 - 0s - loss: 0.5576 - f1_score: 0.7147 - val_loss: 0.6195 - val_f1_score: 0.5782\n",
      "Epoch 72/500\n",
      "17/17 - 0s - loss: 0.5616 - f1_score: 0.6962 - val_loss: 0.5682 - val_f1_score: 0.6855\n",
      "Epoch 73/500\n",
      "17/17 - 0s - loss: 0.5604 - f1_score: 0.7312 - val_loss: 0.6397 - val_f1_score: 0.5782\n",
      "Epoch 74/500\n",
      "17/17 - 0s - loss: 0.5553 - f1_score: 0.7012 - val_loss: 0.5668 - val_f1_score: 0.6470\n",
      "Epoch 75/500\n",
      "17/17 - 0s - loss: 0.5554 - f1_score: 0.7283 - val_loss: 0.5934 - val_f1_score: 0.6398\n",
      "Epoch 76/500\n",
      "17/17 - 0s - loss: 0.5596 - f1_score: 0.7097 - val_loss: 0.7456 - val_f1_score: 0.5708\n",
      "Epoch 77/500\n",
      "17/17 - 0s - loss: 0.5612 - f1_score: 0.7177 - val_loss: 0.6867 - val_f1_score: 0.5747\n",
      "Epoch 78/500\n",
      "17/17 - 0s - loss: 0.5742 - f1_score: 0.6709 - val_loss: 0.5314 - val_f1_score: 0.7086\n",
      "Epoch 79/500\n",
      "17/17 - 0s - loss: 0.5624 - f1_score: 0.6856 - val_loss: 0.5649 - val_f1_score: 0.6855\n",
      "Epoch 80/500\n",
      "17/17 - 0s - loss: 0.5582 - f1_score: 0.7207 - val_loss: 0.4783 - val_f1_score: 0.6607\n",
      "Epoch 81/500\n",
      "17/17 - 0s - loss: 0.5457 - f1_score: 0.7301 - val_loss: 0.5131 - val_f1_score: 0.6455\n",
      "Epoch 82/500\n",
      "17/17 - 0s - loss: 0.5828 - f1_score: 0.6818 - val_loss: 0.4726 - val_f1_score: 0.6421\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 - 0s - loss: 0.5585 - f1_score: 0.7047 - val_loss: 0.6044 - val_f1_score: 0.6186\n",
      "Epoch 84/500\n",
      "17/17 - 0s - loss: 0.5545 - f1_score: 0.7052 - val_loss: 0.5682 - val_f1_score: 0.6560\n",
      "Epoch 85/500\n",
      "17/17 - 0s - loss: 0.5381 - f1_score: 0.7447 - val_loss: 0.5151 - val_f1_score: 0.7024\n",
      "Epoch 86/500\n",
      "17/17 - 0s - loss: 0.5406 - f1_score: 0.7260 - val_loss: 0.5817 - val_f1_score: 0.6305\n",
      "Epoch 87/500\n",
      "17/17 - 0s - loss: 0.5635 - f1_score: 0.7026 - val_loss: 0.5212 - val_f1_score: 0.6912\n",
      "Epoch 88/500\n",
      "17/17 - 0s - loss: 0.5654 - f1_score: 0.6815 - val_loss: 0.7022 - val_f1_score: 0.5747\n",
      "Epoch 89/500\n",
      "17/17 - 0s - loss: 0.5821 - f1_score: 0.7242 - val_loss: 0.4385 - val_f1_score: 0.6022\n",
      "Epoch 90/500\n",
      "17/17 - 0s - loss: 0.5620 - f1_score: 0.7245 - val_loss: 0.4719 - val_f1_score: 0.6421\n",
      "Epoch 91/500\n",
      "17/17 - 0s - loss: 0.5555 - f1_score: 0.7216 - val_loss: 0.5264 - val_f1_score: 0.7036\n",
      "Epoch 92/500\n",
      "17/17 - 0s - loss: 0.5395 - f1_score: 0.7217 - val_loss: 0.5688 - val_f1_score: 0.6632\n",
      "Epoch 93/500\n",
      "17/17 - 0s - loss: 0.5435 - f1_score: 0.7265 - val_loss: 0.5233 - val_f1_score: 0.7036\n",
      "Epoch 94/500\n",
      "17/17 - 0s - loss: 0.5420 - f1_score: 0.7418 - val_loss: 0.4805 - val_f1_score: 0.7044\n",
      "Epoch 95/500\n",
      "17/17 - 0s - loss: 0.5462 - f1_score: 0.7167 - val_loss: 0.5206 - val_f1_score: 0.7008\n",
      "Epoch 96/500\n",
      "17/17 - 0s - loss: 0.5421 - f1_score: 0.7107 - val_loss: 0.5191 - val_f1_score: 0.6455\n",
      "Epoch 97/500\n",
      "17/17 - 0s - loss: 0.5865 - f1_score: 0.6786 - val_loss: 0.5162 - val_f1_score: 0.7183\n",
      "Epoch 98/500\n",
      "17/17 - 0s - loss: 0.5544 - f1_score: 0.7081 - val_loss: 0.5793 - val_f1_score: 0.6327\n",
      "Epoch 99/500\n",
      "17/17 - 0s - loss: 0.5422 - f1_score: 0.7254 - val_loss: 0.5398 - val_f1_score: 0.6931\n",
      "Epoch 100/500\n",
      "17/17 - 0s - loss: 0.5398 - f1_score: 0.7185 - val_loss: 0.4953 - val_f1_score: 0.7024\n",
      "Epoch 101/500\n",
      "17/17 - 0s - loss: 0.5454 - f1_score: 0.7225 - val_loss: 0.5300 - val_f1_score: 0.7024\n",
      "Epoch 102/500\n",
      "17/17 - 0s - loss: 0.5624 - f1_score: 0.7219 - val_loss: 0.7239 - val_f1_score: 0.5890\n",
      "Epoch 103/500\n",
      "17/17 - 0s - loss: 0.5494 - f1_score: 0.7158 - val_loss: 0.4617 - val_f1_score: 0.6531\n",
      "Epoch 104/500\n",
      "17/17 - 0s - loss: 0.5339 - f1_score: 0.7134 - val_loss: 0.5497 - val_f1_score: 0.6855\n",
      "Epoch 105/500\n",
      "17/17 - 0s - loss: 0.5354 - f1_score: 0.7235 - val_loss: 0.5731 - val_f1_score: 0.6345\n",
      "Epoch 106/500\n",
      "17/17 - 0s - loss: 0.5302 - f1_score: 0.7156 - val_loss: 0.5519 - val_f1_score: 0.6487\n",
      "Epoch 107/500\n",
      "17/17 - 0s - loss: 0.5324 - f1_score: 0.7312 - val_loss: 0.5325 - val_f1_score: 0.6762\n",
      "Epoch 108/500\n",
      "17/17 - 0s - loss: 0.5503 - f1_score: 0.6890 - val_loss: 0.5004 - val_f1_score: 0.7024\n",
      "Epoch 109/500\n",
      "17/17 - 0s - loss: 0.5561 - f1_score: 0.7278 - val_loss: 0.7035 - val_f1_score: 0.5712\n",
      "Epoch 110/500\n",
      "17/17 - 0s - loss: 0.5463 - f1_score: 0.7249 - val_loss: 0.4145 - val_f1_score: 0.5793\n",
      "Epoch 111/500\n",
      "17/17 - 0s - loss: 0.5670 - f1_score: 0.6861 - val_loss: 0.7377 - val_f1_score: 0.5663\n",
      "Epoch 112/500\n",
      "17/17 - 0s - loss: 0.5388 - f1_score: 0.7293 - val_loss: 0.4969 - val_f1_score: 0.7103\n",
      "Epoch 113/500\n",
      "17/17 - 0s - loss: 0.5255 - f1_score: 0.7235 - val_loss: 0.5551 - val_f1_score: 0.6855\n",
      "Epoch 114/500\n",
      "17/17 - 0s - loss: 0.5591 - f1_score: 0.6912 - val_loss: 0.5130 - val_f1_score: 0.6946\n",
      "Epoch 115/500\n",
      "17/17 - 0s - loss: 0.5411 - f1_score: 0.7226 - val_loss: 0.5209 - val_f1_score: 0.7008\n",
      "Epoch 116/500\n",
      "17/17 - 0s - loss: 0.5337 - f1_score: 0.7243 - val_loss: 0.6470 - val_f1_score: 0.5782\n",
      "Epoch 117/500\n",
      "17/17 - 0s - loss: 0.5410 - f1_score: 0.7127 - val_loss: 0.4850 - val_f1_score: 0.6804\n",
      "Epoch 118/500\n",
      "17/17 - 1s - loss: 0.5330 - f1_score: 0.7303 - val_loss: 0.5778 - val_f1_score: 0.6204\n",
      "Epoch 119/500\n",
      "17/17 - 0s - loss: 0.5333 - f1_score: 0.7242 - val_loss: 0.5311 - val_f1_score: 0.6958\n",
      "Epoch 120/500\n",
      "17/17 - 0s - loss: 0.5565 - f1_score: 0.6993 - val_loss: 0.4990 - val_f1_score: 0.7044\n",
      "Epoch 121/500\n",
      "17/17 - 0s - loss: 0.5540 - f1_score: 0.6934 - val_loss: 0.5936 - val_f1_score: 0.6136\n",
      "Epoch 122/500\n",
      "17/17 - 0s - loss: 0.5222 - f1_score: 0.7258 - val_loss: 0.6247 - val_f1_score: 0.5962\n",
      "Epoch 123/500\n",
      "17/17 - 0s - loss: 0.5454 - f1_score: 0.6847 - val_loss: 0.5333 - val_f1_score: 0.6855\n",
      "Epoch 124/500\n",
      "17/17 - 0s - loss: 0.5272 - f1_score: 0.7248 - val_loss: 0.5187 - val_f1_score: 0.7036\n",
      "Epoch 125/500\n",
      "17/17 - 0s - loss: 0.5276 - f1_score: 0.7418 - val_loss: 0.4501 - val_f1_score: 0.6788\n",
      "Epoch 126/500\n",
      "17/17 - 0s - loss: 0.5256 - f1_score: 0.7244 - val_loss: 0.5480 - val_f1_score: 0.6794\n",
      "Epoch 127/500\n",
      "17/17 - 0s - loss: 0.5349 - f1_score: 0.7214 - val_loss: 0.6286 - val_f1_score: 0.5907\n",
      "Epoch 128/500\n",
      "17/17 - 0s - loss: 0.5304 - f1_score: 0.7139 - val_loss: 0.5130 - val_f1_score: 0.7116\n",
      "Epoch 129/500\n",
      "17/17 - 0s - loss: 0.5155 - f1_score: 0.7243 - val_loss: 0.4821 - val_f1_score: 0.7044\n",
      "Epoch 130/500\n",
      "17/17 - 0s - loss: 0.5285 - f1_score: 0.7254 - val_loss: 0.6145 - val_f1_score: 0.5907\n",
      "Epoch 131/500\n",
      "17/17 - 0s - loss: 0.5278 - f1_score: 0.7312 - val_loss: 0.5022 - val_f1_score: 0.7024\n",
      "Epoch 132/500\n",
      "17/17 - 0s - loss: 0.5420 - f1_score: 0.7051 - val_loss: 0.5634 - val_f1_score: 0.6274\n",
      "Epoch 133/500\n",
      "17/17 - 0s - loss: 0.5254 - f1_score: 0.7323 - val_loss: 0.4922 - val_f1_score: 0.7198\n",
      "Epoch 134/500\n",
      "17/17 - 0s - loss: 0.5173 - f1_score: 0.7380 - val_loss: 0.5449 - val_f1_score: 0.6780\n",
      "Epoch 135/500\n",
      "17/17 - 0s - loss: 0.5182 - f1_score: 0.7332 - val_loss: 0.5702 - val_f1_score: 0.6327\n",
      "Epoch 136/500\n",
      "17/17 - 0s - loss: 0.5223 - f1_score: 0.7204 - val_loss: 0.5608 - val_f1_score: 0.6416\n",
      "Epoch 137/500\n",
      "17/17 - 0s - loss: 0.5180 - f1_score: 0.7332 - val_loss: 0.4802 - val_f1_score: 0.6728\n",
      "Epoch 138/500\n",
      "17/17 - 0s - loss: 0.5495 - f1_score: 0.6882 - val_loss: 0.4753 - val_f1_score: 0.6886\n",
      "Epoch 139/500\n",
      "17/17 - 0s - loss: 0.5439 - f1_score: 0.7119 - val_loss: 0.5468 - val_f1_score: 0.6855\n",
      "Epoch 140/500\n",
      "17/17 - 0s - loss: 0.5236 - f1_score: 0.7103 - val_loss: 0.5543 - val_f1_score: 0.6706\n",
      "Epoch 141/500\n",
      "17/17 - 0s - loss: 0.5184 - f1_score: 0.7255 - val_loss: 0.5891 - val_f1_score: 0.6116\n",
      "Epoch 142/500\n",
      "17/17 - 0s - loss: 0.5255 - f1_score: 0.7144 - val_loss: 0.5269 - val_f1_score: 0.6632\n",
      "Epoch 143/500\n",
      "17/17 - 0s - loss: 0.5138 - f1_score: 0.7448 - val_loss: 0.5097 - val_f1_score: 0.6780\n",
      "Epoch 144/500\n",
      "17/17 - 0s - loss: 0.5407 - f1_score: 0.7060 - val_loss: 0.5910 - val_f1_score: 0.6208\n",
      "Epoch 145/500\n",
      "17/17 - 0s - loss: 0.5268 - f1_score: 0.7012 - val_loss: 0.6486 - val_f1_score: 0.5819\n",
      "Epoch 146/500\n",
      "17/17 - 0s - loss: 0.5243 - f1_score: 0.7165 - val_loss: 0.4823 - val_f1_score: 0.6946\n",
      "Epoch 147/500\n",
      "17/17 - 0s - loss: 0.5177 - f1_score: 0.7439 - val_loss: 0.6590 - val_f1_score: 0.5853\n",
      "Epoch 148/500\n",
      "17/17 - 0s - loss: 0.5329 - f1_score: 0.7293 - val_loss: 0.4721 - val_f1_score: 0.6804\n",
      "Epoch 149/500\n",
      "17/17 - 0s - loss: 0.5114 - f1_score: 0.7349 - val_loss: 0.5291 - val_f1_score: 0.6780\n",
      "Epoch 150/500\n",
      "17/17 - 0s - loss: 0.5220 - f1_score: 0.7468 - val_loss: 0.5978 - val_f1_score: 0.5995\n",
      "Epoch 151/500\n",
      "17/17 - 0s - loss: 0.5312 - f1_score: 0.7136 - val_loss: 0.7228 - val_f1_score: 0.5780\n",
      "Epoch 152/500\n",
      "17/17 - 0s - loss: 0.5229 - f1_score: 0.7264 - val_loss: 0.4861 - val_f1_score: 0.7036\n",
      "Epoch 153/500\n",
      "17/17 - 0s - loss: 0.5135 - f1_score: 0.7458 - val_loss: 0.4840 - val_f1_score: 0.7024\n",
      "Epoch 154/500\n",
      "17/17 - 0s - loss: 0.5169 - f1_score: 0.7241 - val_loss: 0.5606 - val_f1_score: 0.6345\n",
      "Epoch 155/500\n",
      "17/17 - 0s - loss: 0.5060 - f1_score: 0.7254 - val_loss: 0.5172 - val_f1_score: 0.6946\n",
      "Epoch 156/500\n",
      "17/17 - 0s - loss: 0.5298 - f1_score: 0.7119 - val_loss: 0.6368 - val_f1_score: 0.5924\n",
      "Epoch 157/500\n",
      "17/17 - 0s - loss: 0.5144 - f1_score: 0.7361 - val_loss: 0.4444 - val_f1_score: 0.6631\n",
      "Epoch 158/500\n",
      "17/17 - 0s - loss: 0.5382 - f1_score: 0.7020 - val_loss: 0.5239 - val_f1_score: 0.6632\n",
      "Epoch 159/500\n",
      "17/17 - 0s - loss: 0.5175 - f1_score: 0.7507 - val_loss: 0.4838 - val_f1_score: 0.6958\n",
      "Epoch 160/500\n",
      "17/17 - 0s - loss: 0.5130 - f1_score: 0.7410 - val_loss: 0.5012 - val_f1_score: 0.6958\n"
     ]
    }
   ],
   "source": [
    "#Clone BTC pre-trained model in order to further train it with another target coin data\n",
    "further_trained_btc_model = tf.keras.models.clone_model(btcoin_model)\n",
    "\n",
    "#Compile it\n",
    "further_trained_btc_model.compile(loss=\"binary_crossentropy\", optimizer='adam', \n",
    "                      metrics=[tfa.metrics.F1Score(average='macro', num_classes=pred_range*2)])\n",
    "\n",
    "#Define early stopping\n",
    "stp_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "#Train it\n",
    "further_train_model_hist = further_trained_btc_model.fit(LSTM_training_inputs[:-pred_range], LSTM_ranged_training_outputs,\n",
    "                                       validation_data=(LSTM_validation_inputs[:-pred_range], LSTM_ranged_validation_outputs), \n",
    "                                           callbacks=[stp_early],\n",
    "                                        epochs=500, batch_size=64, verbose=2, shuffle=True, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = r'C:\\Users\\georg\\Documents\\mine\\εργασιες\\μεταπτυχιακό\\2ο εξάμηνο\\Βαθιά Μηχανική Μάθηση\\Γιαννακόπουλος\\temp'\n",
    "create_plot(further_train_model_hist, log_dir, 'ADA')\n",
    "create_F1_macro_plot(further_train_model_hist, log_dir, 'ADA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = further_trained_btc_model.predict(LSTM_validation_inputs[:-pred_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6957674462645582"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(LSTM_ranged_validation_outputs, np.round(preds), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAHRCAYAAABtim1zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABHPklEQVR4nO3dd7wcVf3/8dfb0EINxUAQBCkiFoqAdAiEZgMsiCBKEMWuCH4VQQG7X/kqdn8GlEQEpDdBioHQpEPoICqhhk6I1CTcz++Pc5Ysm9279e7euft+3sc85u7MmTlnZ2d3P3vOmTOKCMzMzMz6zet6XQAzMzOzXnAQZGZmZn3JQZCZmZn1JQdBZmZm1pccBJmZmVlfchBkZmZmfclB0DAgabykkHRkxfJpkoZsDANJE3O+E4cqj6LKx2Var8thw/O1kLR6LtfkXpelXZ16LrU+x4ZSK+eGpMl5u9WHplTFJmmGpBm9Lke3NB0ESTosn0AhaZ1B0k0sS1eanpP0kKS/S/qupLUbzPOfeft/NFveftaLDyUb2fwFYsOdpCPzOTq+C3lV+54LSf+VdJOkQyUtXpZ+co30taZpZdu+TtKHJZ0u6UFJL0l6XtJdkiZJ2nKon28zhuOPl2oWaiaxJAH7AwEI+DTwtTqb3QKclf8fDYwFNgW+DRwm6VfA1yJiXo08twPWznluLuntEXF7M+UusE8Ai9dN1bozgWuAmUOYR1GtC7zQ60IY4NfCahsu50b599zrgJWA9wM/AHaRtF1EvJLTzKjYdjywLXAZMK1i3QwASSsBpwFbAv8FLgb+TfoeXhvYC/i0pC9HxK869aT6QVNBELAT8CZgMvBuYF9Jh0bEnEG2mR4RR1YuzMHNZOArwGLAZ2tsf0Ce/wT4Rn785SbLXUgR8cAQ7/9Z4NmhzKOoIuLuXpfBEr8WVsswOjcW+J6TNAa4Fdg6T9Mi4izmB0uldEeSgqBpNb4rFwcuANYH/gJ8PiKeqUizNKlCYukOPJe+0mxz2Kfz/BjgBGAF4AOtZBwRlwI7A3OAAyS9szKNpOXz/u8FvgU8BuwjabFm8iqvHpW0r6SbJb0o6XFJf8xRduU20/I2i0g6XNI9kl4ubzeXtIqkX0v6T173lKRzJG1SoxwrSvqDpMdy/tMl7TtIuWv2CZK0k6Rz83N4OVePni1ph7x+MnBpTn5ERRXr+JymZp8gSRvlatfS/u+X9FtJ46qkfbWJRNJnJN2Wq2ofy9W0y1TZZj1JJym1P78s6YlcffxzSQvXOiZl2w/a1Kcq7dr5tfxyzucZSS/kdK8et7K0C1TlVpxHH5Z0Xd7H05L+IukNNcqyiaSLlKrIZys1B2+uJqvty47zGpIOknR3Ps4PSTo6fxBWPQ6Slpb0s/z/3PLjJukted8P5tfiMUknqqK5O5+LpfP1vrLzaUZZmkHfN5KWkfQ/ki7J5Z6TX/tzJG1W43l38rVYTtKPlJoQXpT0rKSpknaqkX6pfNweysf6bkkH0eRnZ/n5KmljSRfkvJ9Rep+tmtOtkcv/RC7fpZLWr7HPcZJ+k1/T0nE8Q9JGnXoukhaX9E2lz6rnlbo0XC1pr2aef5X97pyPxw8qlm9fdl6tWrHulNL5X7asssloBnBEfnhp2b5qfY429HnVioiYBVyfH76+jV19lRQAXQV8rDIAynnNjojDgf9rZIdKvijpjvzcH1b6Lqv63Jt53yp/r+SH2+q13z1HVqQ7Xen780Wlz8arJO3T2GHpjIZrgiStCOwK/DMi/iFpNnAQqWbm5FYyj4i7JZ0C7EOqzrupIsm+wKLA5IiYJ+mEnOcewPEtZPlVUm3WyaTIeitgP2C8pE0j4okq25wObAL8jRTBPw6gFLRdBCwHXAicQQoKdweulPSBiDi/tBOlgO4fwBrAlXkaB/y/vJ+GSfoOcDjwXC7Tg8DKwBakY/l35v/a2JcFq1ln1Nn/+/LzFqkK9n5gI+BzwG6StoyIavv4CSmwPTc/p+1IgfNawPZl+18PuJbUxHkOcB/pF8xawOdJAe/cwcrYosmk8+x24E/Ai6TjthWwC+m4NeLzpPfCOaRjuymwJ7C+pA0i4uVSQklbk47FwqRj+m/gHaQA9ZIWn8fRwDbAKcDZpGN+ILC1pK0i4qWK9IvkvJbLZZlNOuZI2oV07i5Met3+BawCfBB4r1I1ful9+R3S+b0+8AtgVl5emper+r4hNV/8ALgcOA94Bngj6Xi+W9L7I+KCJo5FM6/FaqT3werAFaTPgCWA9wEXSPpMRBxTln5RYGp+HreQfviNITXlb9tEGcttQqrRvoz0Y/IdpGP9Dkm7kj4X7iadn6vldRdLWiMinisr25ty2pVJr+1JwKqkz8b3SvpQRPy1neeiVJNxCbAh6bP5j6SAaWfgRElvi4hvtXgcriD9AJ4AHFa2fPuy/yeQ3rOlrhjjgRkR8Z9B9vtz0jm6LTCFwT/rGvq8alUOKDYBBoCb29hVqTXkexExMFjC8vO9jp+TWlRmApNIn7e7kd4/i5Bem3LNvG+nkz4rjiB9d0wu28+0sv9/B9yZ9zkTWB54D3C8pHUi4tsNPpf2RERDE3AI6Uvrm2XLbiS9wGtVST8xp59cZ7+lPkaXVVl3J/AKsEp+/Pac9opGy523OzJvNwfYsGLd0XndHyqWT8vLbwVWqFi3EOnL4iVg24p1KwMPk17URcuWT8r7O7oi/cakEzCAI6uVoWLZTjntf4A3VHmuq5T9P77afqu8RhPLli0JPJmP+9YV6b+R019UsXxyXv4A8MaK43R5XveusuU/zct2q1KmZYHXNfCa1ntuM0gfmKXHy+Rz9QZgVJX0y1c8DlL1dLXzaDbwjop1J+Z1Hylb9jpSLWYA765I/9m8PIDxDZ7HpeP8JLBaRT6n53XfrnIcghTgLVHlWD+T9/fWinVvIwXZN9Uow+o1yjiNGu+bsteh2vJVgEeAu6qsa/u1KCvbAPDRiuVjSB/cLwIrli0/NO/n9PJzktQl4Gka+Hyrcr4G6dd8+bo/5OVPA4dVrPt2XveViuUX5uWV6bcA5gFPAUu281zKXuuvVyxfjBRADgAbNPqerHJMLs9lXaZs2dWkgOtJ4Piy5etT/XN6sHOj6vuKJj+v6jyHiTn99JzvkcB3gd+TvgeeA75QZx+l8i5w3EiBbZC+IxZrpEwNlHmLvM9/ActVvK5X53UzhuJ9W7F+zSrLFiEF63Op8v02FFNDVbo5Cv9UPun/VLZqMqm24FON7KeGh/P8NdWFkrYhRZ9/j4iHACJ1iL4J2ErSui3kdXxE3Fyx7EhSv5i986+lSt+OiCcrlr0XWBP4VURcVr4iIh4h/cJYifRLBqXmnY+ROrQdWZH+BtKvskZ9Kc8PjoiHK1eWjlUbdiNF5CdHxBUV635K+lLdUdIbq2z73SjrxxSps/tx+eG7qqR/sXJBRDwTdX7ttChI5+rLpPO4Mt+nmtjXLyPitoplpRqE8ue5BelX5aUR8beK9JOAfzaRZ7lfRMT9pQf5eP0P6Xl9ssY2B0fE8xXLPkEKAI6IiDvLV0TEHaTntKGkt7ZQxmrvGyLi2RrLHyLVOr6lxrlVS0OvRW5S2hY4PSL+UpH3LNKv1sWAD5Wt2o90TL9efk5GxH3AL5soY7krI6Ly/T4lz58FflyxrvR5u0FpgaRVSD+GHiB91rwqIv5BqhVajlSLVNLUc8k11/sAN0REZR4vkX4QCdi7xvNsxFRgFLkmStJSpB+FF5NqSieUpZ1Qtk2nNPt5NZj1SefQEaTA9QDSD+JzaL3GF1JrAcBTsWANb6v2y/MfRMTTpYV5/9+stsEQvG+JiH9XWTYH+A0pIJ2wwEZDoNHmsO1JX/oXVnzxnkhqg5wo6dsR0UoThvI8KpaX+h8dV7F8MvDOvP6gJvO6rHJBRDwraTrpjbguKaIvd12V/Wye56upep+U0qX/6wLnA28hXeV1RaTOyJWmMb+vRT2bkY5VM00GzSj1zVrgjRupSfJyUnPChqQP4XI3VNnfg3m+bNmyk0kd4s+SdBqpluKqam+KTomI2ZLOJV2xMV3S6aQq+WsjotmrSxp9nhvm+ZVVyjOgNOTDm5vMG6qfx/+R9CCwuqQx+Yu95CVSzUyl0nm8fo3zuFS2dUm1ss2o9r4BQOlS3q/k/MeSfv2VewMLnlu1NPpalJ7rMjWea+lH2Lq5jEuRAtgHa5yX05jf96QZ1cr7SJ5Pj3QFUbnS5+0qZctK59UVNT5zLyEFMBsCf2rxuWxCClBq9bsr9dtr5cdoeTmPJH3ZnUP6DF6IFOjMAD4sad2IuIv5zVPtBBSVGj13GjElIiaWHuTuIzuQmo3fJ2l8zG9Wbkat78d2lD7jF/gcIX0m1rpSu5PvW3LQ9A3S6/9G0tXjlfsbco0GQaU2ycnlCyPiqfzF8iFSDcJpLZRh5Tx/tT+OpGWBD5P6GpxVkb4UeH1C0jej8TZQSB2rq3k0z5cZZF255fN8jzr5LVmx33r5N2IM8ExELFCL0iGlsta6bL60fEyVdbOqLCu9oUaVFkTEdbmvzGGk1/njAJLuAb4TESc1V+SG7Ul60+1NarMGeCkHYl+LiFqvT6VZVZYt8Dyp/7o3ml+j2z1K6keyDK8t4+OR65orlM7jT1dZV27JOutrlWUBkj5A+px4ifmX+T5PqqUYT/oirFYjW8usKsuqvRal57pjnmoZivdsuWo/gubVWpd/eMD8oKO8bI2+R1t5LqXjtUmeamnl3Ci5hvTal37xTyB1WbiS+X15Jki6l9QH7s6IaPW4VzOryrJq507T8mfJCZJGk2omf0Tqf9SsUoC8gqTFOlQbVPN8iIhXJC1QK97p923u3H4dKdi8gtQn61lSN4zVmd8feMjVDYIkvZ7U0QzgJEm1vqAOoLUgaLs8v7Zs2SdIVdOLAS/mD4FKy5OCrxObyGvFGstLV4dV+xCq9uVRSrdbRJzTQL6l9PXyb8QsYHlJo4coECqVtVaZxlWka0lEXE36hbQoqdP1LqSmvhMlPRER9Topl6r0a53Dy1SWMR+vI4Ejla482YbUpr8P6Y23ddNPZHCz87zW615reT0rAvdUWV7rPK71K7KUbv2IqFZT1LIa7xuA75G+6DbOv/BfJen3tN7huJ7Sc/1KRDTSlNXJ92ynNfsebeW5lLY5OiKarXFvSETMlXQlsLPSVacTgKtzzew/JT1Eqk25CViKztYCdUvpe63Z5jUAIuJBSQ+Qakq2ocmLaGooPx9e08lc0ijSd2tlV4tOv28PyvnsFxGTK/a3F423jLStkT5B+5KqvW4kdeCrNj0B7JCvWGiYpLeQalOC1wYzpV+mJ9XI77SKdI1a4IXKPfg3IEW4d1Wur+GaPG/0S/Nu0oBeG9S4BHF8g/sp5S1S0FBPqWq9mV81pT5TC5RJ0kKkK6lgwSv5WhIRL0fEPyJd3lka/2m3BjZ9Js9XrVwhaS2q11SV5/tg7puxM6nz8la5H0QnlY7lVpUrJL2O1GeoFdXO4zVIx2JGRVPYYJo9j6G1c6rcWqRf9JUfpK+jynHqoKaea0T8l9Rx9A2S1qySZHyHytWKV8+r/J6sVPpheRO0/FyuI/3Q6PQPg0qlPj4fJV34Ut7n5xJS2XasSFtPu+doJ5Wa1dq5RdWkPP9Wfp/UVKNfa6XSZ3e1wGVrqv+wbOV9O0Dt12CtPD+9yrqh+iFUVSMvTKnT8+cj4lPVJlJP+KY6SEvaltSvZRHgdxFxS16+BenKlLsiYu8a+e1JuvRuvKRm+lR8XNKGFcuOJNUanNRE09rZpOrAL0h6T43nt7nycOm53f4E0q+ZIyvSbUzqNN2o0migP1WVsVAqlpWqNZvpsHYW6WqRvbTguC0Hki7x/3u0MZCjpK1rBIOlX6qN9NG5m1TTspuksWX7Hk31jp6vl7Rplf0sQXpd5rHgZaHtuop0nmwn6d0V6w6gtf5AAF/Jl3sDr34QHUV6P1f2oRvMcaSaxSMkLfBLVWmY/vEVi1s5p8rNANaWVGoGL114cQTQSgfshuQLEK4APiipaudxSe8oP5dIx+d1wP+Wf/nkH3s9G7A1d0a9mFR7eWD5unyO7036kXBm2aqmnktEPE76zNpY0rerBVuS1mz2h28VpdqdQ0jfIZVB0DKkYRAGWHA05VraPUc7IteqfCU/nNbGro4mDWuwNamP15gqeS0p6XDq38EB5ndrOUzScmX7WIzUbFfNDJp/3z5FlR+pZfuDigBc0s60d6FV0wZtDssfgOsAt0VEzY6OpNqZw4D9JB0Rr70FxgZlHesWJX3RbUo6cAPAz4Cvl6Uv9T86tlZmuVPpcaSA4tOkK2Ma8TfgKqWxiWaSItitSC/IIQ3uo1SN+0HSZarn5Q6u00lf3quS2tDXIFVLl77QDyVV9x6YA5/SOEF7kjpP79pg3hdJ+h7pCoS7JJ1F6sy3Yn4u15CaeCA1mTwMfFTSHFKntSBdJXc/VUTEc/lL4lTgMkmn5u02Il2R8ijwmUbKOoiDgZ2UBjn7D+ky0reRRiF/hvm/fGrKr8EvSMfhZklnks7nHUnt6I9UbPIG4BpJd5F+CT1IGpvofaTmgF/mX8wdk8/TT5GC/XOUOmP/G1gvl/NvpOfc7NVwV5E6d59MqtremXR1yo1UXC1Up3xPSfow+fYpkqYCd+TyvJHUAXJ5UrN0yVTS++2Y3JfqOWBWRPy6wWyPJo2NdXM+HnNJtwJ4K2m8lvc3Wv4W7E36Yv2DpC+TmipmkTodr0eqidic+WMa/ZTUFeBDwE2SLiR9Ke9JupS6offsEPks6Tw4SmmgxxuYP07QAKmZofx8buW5fJF0kcd3ST8gryT1I1mZ1CF6E9K4W/e18TxuJv3oGks6l8q/Z0oB0VjSVWqzGtznpaRj8CNJbyfXGkfE99soZz3l33OQyrw96fvzSV77HdeUiHhBaTyv00g/mN8v6WJS7d7rSLUqE0ifZ19sYH9XKd2u6kvA7fl9XBon6Bmq9zVr5X07lfTdcy7ps2kecHlEXA78lnSV2ql5fw+T3n+7kMY/27Pe8+iYGHw8gRNIX5pfHixdTntRTvuBeO34CeXT88BDpKuBvkPF+EKkN+XzpMuYFxiToCLtqqRqz8eBReqkPTLnPz6Xazrp8uwnSL+QxlXZZhoVY/RUSTOWdEnr7aRg5zlS08pppH4mC1WkX4k04NgTOf/puTzjaXCcoLJ17yF9uT6dj9eDpC+z7SvSbUI6GZ8lfTAEefwMqowTVLHdmbmspQDqd8DKVdJOpsbYMdWeGymYOo50xdGz+TW/h1SDs1q9c61sPyIFr/8uK+NPSFfizeC14wSNIQ0weQnpDfcy6c0+jfRBrop9B02MP0L6VR5UGTeGFPRfTBoi4b+k839z4Nd5mw0afL6l47wGKZC8m9SM+zBp8LOlq2zzmuNQY7+r57Lcm/c3O+/7eGD3KukPIjUdv0zFmCI09r6ZSDr3nyd9QZxJGjSw6vHt8GuxFOkHyY2k9+uLpC/x80g/wCrHUlqa9EPt4Xxs7s7Hfo1aedR4zuOpPRZMzfLWev55+RtI78n7Sef/k6Sa3E1q7Kfp50Kqqf8iaaDXZ/Nr/gDpM+VAysbXGuw51jk2pTGuzquy7p687n+bPDb7MP9zPsrPSZr8vGrgXK78nouc712k9+UCn5k1zuVB8yQFPHuQBjd9KL+GL+TX8VhgiyaOufLrWnofP0K6NH0Zanxm0Pz7diypm8tjpO/qyu+BLUifx8+QPhevJAXqLZ1HrU7KhRnRcoR+BLBdREzrbWnMEklXkQKkZWLBMXyqpZ9M6qP3pqg+YreZmTWhnc5aZlaH0r2XxlRZPpH0S+iiRgIgMzPrvGbvIm9mzXkjqR291Ia/EGkQu61I/VEO7l3RzMz6m4Mgs6H1GKlv3bakS5cXJXUuP440bP2QjZJtZmaD64s+QWZmZmaV+qImaL2VNnekZ9YDdz7d8nBSZtameXMernq7haEy98n/dOy7duEV1uhK2d0x2szMzPpSX9QEmZmZ2RAbeKV+mmHGNUFmZmbWl1wTZGZmZu2LZu8A1HsOgszMzKx9A8ULgtwcZmZmZn3JNUFmZmbWtnBzmJmZmfUlN4eZmZmZFYNrgszMzKx9bg4zMzOzvuTBEs3MzMyKwTVBZmZm1j43h5mZmVlf8tVhZmZmZsXgmiAzMzNrmwdLNDMzs/7k5jAzMzOzYnBNkJmZmbXPzWFmZmbWlzxYopmZmVkxuCbIzMzM2ufmMDMzM+tLvjrMzMzMrBhcE2RmZmbtc3OYmZmZ9SU3h5mZmZkVg2uCzMzMrG0RxRsnyEGQmZmZta+AfYLcHGZmZmZ9yUGQmZmZtW9goHPTICStI2l62TRb0oGSlpN0saR783zZekV2EGRmZmbti4HOTYNlE3FPRGwQERsAGwEvAGcChwBTI2JtYGp+PCj3CTIzM7P29eYGqhOAf0fE/ZJ2A8bn5VOAacA3BtvYNUFmZmY2rEg6QNINZdMBNZJ+FDgp/79iRMwEyPOx9fJxTZCZmZm1r4NXh0XEJGDSYGkkLQLsCnyz1XwcBJmZmVn7uj9i9LuBmyLisfz4MUnjImKmpHHA4/V24OYwMzMzK6K9mN8UBnAOsG/+f1/g7Ho7cE2QmZmZta+LgyVKWhzYEfhM2eIfA6dI2h94ANij3n4cBJmZmVn7utgcFhEvAMtXLHuKdLVYw9wcZmZmZn3JNUFmZmbWvu53jG6bgyAzMzNrWxHvIu/mMDMzM+tLrgkyMzOz9rk5zMzMzPpSFy+R7xQ3h5mZmVlfck2QmZmZtc/NYWZmZtaX3BxmZmZmVgyuCTIzM7P2uTnMzMzM+pKbw8zMzMyKwTVBZmZm1j43h5mZmVlfKmAQ5OYwMzMz60uuCTIzM7P2FbBjtIMgMzMza5+bw8zMzMyKwTVBZmZm1j43h5mZmVlfcnOYmZmZWTG4JsjMzMza5+YwMzMz60tuDjMzMzMrBtcEmZmZWfsKWBPkIMjMzMzaF9HrEjTNzWFmZmbWl1wTZGZmZu1zc5iZmZn1pQIGQW4OMzMzs77kmiAzMzNrnwdLNDMzs77k5jAzMzOzYnBNkJmZmbWvgOMEOQgyMzOz9rk5zMzMzKwYXBNkZmZm7StgTZCDIDMzM2tfAS+Rd3OYmZmZ9SXXBJmZmVnbYsBXh5mZmVk/KmCfIDeHmZmZWV9yTZCZmZm1r4Adox0EmZmZWfsK2CfIzWFmZmbWl1wTZGZmZu1zx2gzMzPrSwMDnZvqkDRG0mmS7pZ0l6TNJS0n6WJJ9+b5svX24yDIzMzM2hfRuam+XwAXRMRbgPWBu4BDgKkRsTYwNT8elIMgMzMzKwxJSwPbAH8AiIg5ETEL2A2YkpNNAXavty8HQWZmZta+DjaHSTpA0g1l0wFlOa0BPAEcJ+lmScdKWgJYMSJmAuT52HpFdhBkw8p3jj6MabefxxnT/vya5Xvt/2HOufIvnHHZCXz121/oUenM+sNXvvxpbpl+CdNvnsqfj/8Niy66aK+LZEUwEB2bImJSRGxcNk0qy2kh4J3A7yJiQ+B5Gmj6qsZBkA0r55x8Hp/b66uvWbbJlu9ku5234UPbf5wPbvsxpvzuxB6VzmzkW3nllfjiFz7Jppu9hw02nMCoUaPY8yO79bpYZuUeAh6KiGvz49NIQdFjksYB5Pnj9XbkIMiGlRuvmc6zs2a/ZtlH9v0gf/jV8cydMxeAp598phdFM+sbCy20EKNHL8aoUaNYfPRoZs58tNdFsiKIgc5Ng2UT8SjwoKR18qIJwJ3AOcC+edm+wNn1ilyoIEjSapJ2yP+PlrRUr8tkQ2+1NVZlo83W54Tzj+WPZ/6Wt22wbq+LZDZiPfLIo/zs6P/Hff++joceuJlnZ8/m4r9f3utiWRF0sDmsAV8CTpB0K7AB8EPgx8COku4FdsyPB1WYIEjSp0lVXr/Pi1YBzhok/audqp5+4bEulNCGykILjWKpZZbiY+/5FD/77q/5v0nf73WRzEasMWOWYdf378xab96MVVd7J0sssTh77/3BXhfL7DUiYnruK7ReROweEc9ExFMRMSEi1s7zp+vtpzBBEPAFYEtgNkBE3MsgPb/LO1Utt/iKXSqiDYXHHnmCqedPA+D2m+9kYGCAZZcf09MymY1UEyZszX0zHuDJJ59m3rx5nHnW39h8s417XSwrgBgY6NjULUUKgl6OiDmlB5IWAop3tzZr2iUXXM67tkofwqutsSoLL7wwzzw1q7eFMhuhHnzgYTbd9J2MHr0YANtvtxV3331vj0tlhdDd5rCOKNK9wy6TdCgwWtKOwOeBc3tcJuuw//3dd9h4i3cyZrkxXHzT2fz2qGM586Rz+e7Rh3HGtD8zd848vvXl7/W6mGYj1nXX38wZZ5zH9dddyLx585g+/Q6OOfaEXhfLbEgoGhueuuckvQ7YH9gJEHAhcGw08ATWW2nzYjxJsxHmzqcf6HURzPrWvDkPq5v5Pf/9fTr2XbvEt/7clbIXpiYoIgaAY4BjJC0HrNJIAGRmZmZd0MVmrE4pTJ8gSdMkLZ0DoOmk4bJ/1uNimZmZWUEVJggClomI2cAHgeMiYiNghx6XyczMzKCj9w7rlsI0hwEL5WGwPwIc1uvCmJmZWRk3hw2p75I6Q/8rIq6XtAbg6zbNzMysJYWpCYqIU4FTyx7/B/hQ70pkZmZmr6pzz6/hqDBBkKTFSJfIvw1YrLQ8Ij7Zs0KZmZlZ4uawIXU8sBKwM3AZ6d5h/+1piczMzKywClMTBKwVEXtI2i0ipkg6kdRHyMzMzHqsm/f86pQiBUFz83yWpLcDjwKr9644ZmZm9qoCNocVKQiaJGlZ4NvAOcCSwOG9LZKZmZkVVWGCoIg4Nv97GbBGL8tiZmZmFQpYE1SYjtGSVpT0B0l/y4/fKmn/XpfLzMzMSJfId2rqksIEQcBkUkfolfPjfwIH9qowZmZmVmxFCoJWiIhTgAGAiJgHvNLbIpmZmRmQmsM6NXVJYfoEAc9LWh4IAEmbAc/2tkhmZmYGEAXsE1SkIOgg0lVha0q6Cng98OHeFsnMzMyKqhBBkKRRwLZ5WgcQcE9EzB10QzMzM+sO1wQNjYh4JY8UfTRwR6/LY2ZmZhU8YvSQukrSr4GTgedLCyPipt4VyczMzIqqSEHQFnn+3bJlAWzfg7KYmZlZOTeHDZ2I2K7XZTAzM7MaChgEFWacIEk/lDSm7PGykr7fwyKZmZlZgRUmCALeHRGzSg8i4hngPb0rjpmZmZVERMembilMcxgwStKiEfEygKTRwKI9LpOZmZlBIZvDihQE/RmYKuk4UofoTwJTelskMzMzK6rCBEER8RNJtwI7kAZL/F5EXNjjYpmZmRm4JqgL7gLmRcTfJS0uaamI+G+vC2VmZtbvinjvsMJ0jJb0aeA04Pd50RuAs3pWIDMzMyu0ItUEfQF4F3AtQETcK2lsb4tkZmZmgJvDhtjLETFHEgCSFiJ1kDYzM7NeK96tw4rTHAZcJulQYLSkHYFTgXN7XCYzMzMrqCLVBB0C7A/cBnwGOB84tqclMjMzM6CYHaMLEwRFxICks4CzIuKJXpfHzMzMyhQwCBr2zWFKjpT0JHA3cI+kJyQd3uuymZmZWXEN+yAIOBDYEtgkIpaPiOWATYEtJX21pyUzMzOzZKCDU5cUoTnsE8COEfFkaUFE/EfSPsBFwNE9K5mZmZkBxewTVISaoIXLA6CS3C9o4R6Ux8zMzEaAItQEzWlxnZmZmXVLAccJGrIgSNKywCY5j1sj4qEWd7W+pNnVsgAWa7V8ZmZm1jlFbA5rOgiSNIbUTwfggoj4Z5U0hwCHA4vmRSHpz8BnIuLlZvKLiFHNltHMzMysnlZqgt4D/JzUFHVC5UpJHwN+SLqlhUqLgY8DiwB7t1JQMzMzG8YK2BzWSsfoXfL88oh4qnyF0o29vle26DTg/4D7SYHQnpK2aqWgZmZmNnzFQOembmklCFqPVMtzdZV1WwKr5/XfiIiPRMTXSX2Dns5p9m0hTzMzMxvOujhOkKQZkm6TNF3SDXnZcpIulnRvni9bbz+tBEEr5Pm/qqzbIc9fBH5bWpgvcT+RVBu0WQt5mpmZmZXbLiI2iIiN8+NDgKkRsTYwNT8eVCtB0PJ5/lyVdaWmrssi4oWKdbfl+RtbyNPMzMyGsWHQHLYbMCX/PwXYvd4GrQRBpeItWb5Q0kKk21kEcGWV7UrNYYu3kKeZmZkNZx1sDpN0gKQbyqYDKnIL4CJJN5atWzEiZgLk+dh6RW7l6rBHSf1+3laxfGtgiVywf1TZbqk8r6whMjMzM3tVREwCJg2SZMuIeETSWOBiSXe3kk8rNUE3kPr27CNp+bLlX8rzF6neafrNed7qoIlmZmY2THWzOSwiHsnzx4EzgXcBj0kaB5Dnj9fbTytB0Il5Pg64XtLRki4ktb0FcGpEVLudxRZ5/a0t5GlmZmbDWLeCIElLSFqq9D+wE3A7cA7zr0DfFzi7Xpmbbg6LiLMlnU8aNHE14Mtlq2cDR1Yp8FjS5fMAlzabp5mZmVm2InBmGpqQhYATI+ICSdcDp0jaH3gA2KPejlq9d9iHgR8BE4Fl8rLrgC9ExP1V0h8AjCLVBF3SYp5mZmY2THVrkMOI+A+wfpXlTwETmtlXS0FQRLwEfFXSwcDrgRcjotpNTkv+ClwBDEREtfGFzMzMrMhC9dMMM23dRT4iBoDHGkg3vZ18zMzMzDqtrSDIzMzMDLp7z69OcRBkZmZmbYuBEdQcJmmboco0Ii4fqn2bmZmZNWKwmqBppKu5Oi3q5GtmZmYFMxKbw4pXt2VmZmZdFyPs6rDvdK0UZmZmZl1WMwiKCAdBZmZm1pCR2BxmZmZmVlcRrw5r5QaqZmZmZoXnmiAzMzNrWwzF9eRDzEGQmZmZta2IzWFtBUGSVgM+BmwKrAIsTbpb/GAiItZsJ18zMzOzdrUUBElaCPgJ8CXm9yuqDAGjznIzMzMbIfqpJugY4BPMD3AeBVYiBThP5uXLMT9ACuBh4JWWS2pmZmbDVhH7BDV9dZikrYF988MrgTUjYuWyJJ+OiLHAGOBDwI2koOifwMYR8aa2SmxmZmbWAa1cIv/JPH8e2C0i7quWKCKei4gzSf2FJgPbAWdI8mX5ZmZmI0wMqGNTt7QSkGxBat46ISKeqZc4IgaAA4B/A1sxvxbJzMzMRogIdWzqllaCoHF5fkeN9YtVLoiIecAUUrPY3i3kaWZmZtZRrXSMXjTPZ1Ysfx5YnNQhupp783zdFvI0MzOzYaxf7h02C1iBBWt8ngTeCKxdY7vl83yFFvI0MzOzYWygi81YndJKc9g/83z1iuW3kZq73l1ju53z/NkW8jQzMzPrqFaCoGtJwc5GFcvPz/N1JH2nfIWkrwC7kjpUX9tCnmZmZjaM9UvH6IvyfIKkRcuWn0AaNBHgW5JmSvqHpEeBn5Wl+3ULeZqZmdkw1i+XyE8FLgPuJF0uD0BE/Jd0H7GXSDVFK5LGCBrL/JGlfxQRF2FmZmbWY013jI6IV0gDH1Zbd6mk9YFDgQmkQOgF4HrgVxHx1zbKamZmZsNUEW+b0dZd5KuJiH8xf1RpMzMz6wNFvIGqb2FhZmZmfanjNUFmZmbWf4o4TpCDIDMzM2tbNy9t75SmgyBJh7ebaUR8t919mJmZmbWjlZqgI0mDHrbDQZCZmdkI0k9Xh7VT51XAw2RmZmaD6Zc+QVXHCKrwOtKNUjcFPkG6eepfgEkt5GdmZmbWca0MlnhZE8lPlfQ9UgD0UeDuiPhes3mamZnZ8FbEjtFDPk5QRDwLfAh4BDhC0uZDnaeZmZl1V0Tnpm7pymCJEfECcFzO74vdyNPMzMxsMN0cJ+iOPN+qi3kCMGbU4t3O0syAFx+5otdFMLMu6ZeO0a1aJM/HdjFPMzMz6wL3CRrcznn+bBfzNDMzM6uqKzVBkr4A7EUaI+jabuRpZmZm3dMXzWFN3DZjEWBlYDywGmmAxQB+1WyeZmZmNrwVcSTkbt02oxQefjci/t5CnmZmZjaM9UVNUNbMM50DXAL8X0Rc0mJ+ZmZmZh01VLfNAHgZmAX8KyLmtZCPmZmZFUQRrw4b6ttmmJmZWR8Y6HUBWtDNS+TNzMzMOkLSKEk3S/prfrycpIsl3Zvny9bbR9NBkKTD8/TmJrdbs7Rts3mamZnZ8BaoY1ODvgLcVfb4EGBqRKwNTM2PB9VKTdCRwBHAW5rcbq2ybc3MzGwEGYjOTfVIWgV4L3Bs2eLdgCn5/ynA7vX24+YwMzMzG1YkHSDphrLpgIokPwe+zmu7Iq0YETMB8rzubbq6ee+wUXn+ShfzNDMzsy4YaGr0nMFFxCRgUrV1kt4HPB4RN0oa304+3QyCVsvz2V3M08zMzLqgib487doS2FXSe4DFgKUl/Rl4TNK4iJgpaRzweL0dtdMc1tCo0ZIWl7QV8NW8zd1t5GlmZmZ9LCK+GRGrRMTqwEeBSyJiH+AcYN+cbF/g7Hr7GrQmSNIRQLWruQScJbUU9dUtlJmZmRXLMBgn6MfAKZL2Bx4A9qi3QSPNYbUinVYioCuBX7SwnZmZmQ1jXWwOm59nxDRgWv7/KWBCM9vXC4JmAJUjRG9Lata6E3iyzvYDwHPAfaRr9s+LiGEQLJqZmVm/GzQIiogpzL/mHgBJpSDmsIg4Z6gKZmZmZsVRxBqOVq4Ou5xUE1SvFsjMzMz6RF8EQRExfgjKYWZmZtZV3RwnyMzMzEaoXnSMblfTQZCkpUjDVQuYHBGXN7DNNsBE0mjRX46IF5vN18zMzIavgeLFQC3VBH0U2A94kTQAYiNuAT4CjAauAP7UQr5mZmZmHdPKiNG75PmFEfFsIxvkdH8j1R69t4U8zczMbBgbQB2buqWVIGgD0tVh/2hyu6vzfMMW8jQzM7NhLDo4dUsrQdC4PH+wye0ezvOVW8jTzMzMrKPauTqs2QCqVL/lK9LMzMxGmL4YJ4g0SOIbgDWb3G6tPH+6hTzNzMxsGBto7abqPdVKc9gtpFqdDzW53YdJTX23t5CnmZmZWUe1EgSdn+frSfpiIxtI+hKwXn54Xgt5mpmZ2TDWLx2jJwOP5f+PlvQ9SUtUSyhpCUnfB37G/PuNHdtKQc3MzGz4Gujg1C2t3DvsRUn7AeeSgqhDgS9JuhS4C3gOWBJYF9gOWIrUfPYKsF9EPN+hspuZmZm1rKUrtSLiAkkfA/4ALAEsDeyap3KlXlLPAftHxPmYmZnZiFPE22a00hwGQEScAryD1Lw1mxTwVE6zgd8D60XEqW2X1szMzIalIo4Y3daYPRExAzhA0mdJHZ9XIdUKzQYeAm6NiNc070laKSIebSdfMzMzs3Z1ZODCHOhMz9MCJC1EairbD9gJWLQT+ZqZmdnw0M2rujplSEdvlrQ+KfDZG1ie1ERWxONkZmZmgyhin6COB0GSlgM+Rgp+1i8tLksyu9N5mpmZmTWrI0GQJAHvJgU+7wcW5rWBzzzgIuB44OxO5GlmZmbDR7/cO+xVktYBJgIfZ/7d5UvBTwD3Ar8FToqIJ9rJy8zMzIavIvZ1aToIkrQUsCep1mez8lV5/jDpBqsAJ0bEL9sqoZmZmdkQaDgIkrQdKfD5IDC6tDjPnwfOBP4EXEJq/jIzM7M+MeI6RktajdTctS+wWmlxng+QAp4/AadHxAtl23W8oGZmZjZ8jcQ+Qf/J8/Ko5g5SB+c/R8QjQ1IqMzMzsyFWLwgqjesTwAnAzyJi+lAXyszMzIplJNYElfsIsLSkKcBfI2LuEJXJzMzMCiYK2BOm3g1UjyPdAV7AIqQxgE4DHpX0O0lbDHH5zMzMzIbEoEFQROxPGv9nP+CyvFjAssABwBWS/iXpCElrDmlJzczMbNga6ODULfVqgoiIFyJiSkRsB6wFfB94gBQMCXgTcDjwT0lX5jvKm5mZWR8ZkUFQuYi4LyIOj4jVgR2BE4GXmB8QbQ78pmyT1SX5jvFmZmY27DQVBJWLiKkRsQ+puezzwHXMD4ZKo2fvCzwm6VhJ49srqpmZmQ1X0cGpW1oOgkoiYnZE/L+I2Ax4G/BT4DHmB0RLk/oUTZX0gKQftZunmZmZDS8D6tzULW0HQeUi4q6I+B9gVWBX0q005jI/IFoF+Hon8zQzMzNrRUeDoJKIeCUi/hoRHwJWBg4Cbh2KvMzMzKz3RnzH6FZExFMR8fOI2ADYmNd2nDYzM7MRoIhBUDMjRrctIm4CbupmnmZmZmbVdDUIMjMzs5Gpm1d1dYqDIDMzM2tbN6/q6hQHQWZmZta2It5Ffsg7RpuZmZkNR64JMjMzs7a5T5CZmZn1pYEChkFuDjMzM7O+5CDIzMzM2tatwRIlLSbpOkm3SLpD0nfy8uUkXSzp3jxftl6ZHQSZmZlZ27p4F/mXge0jYn1gA2AXSZsBhwBTI2JtYGp+PCgHQWZmZlYYkTyXHy6cpwB2A6bk5VOA3evty0GQmZmZta2TzWGSDpB0Q9l0QHlekkZJmg48DlwcEdcCK0bETIA8H1uvzL46zMzMzNrWyRGjI2ISMGmQ9a8AG0gaA5wp6e2t5OOaIDMzMyukiJgFTAN2AR6TNA4gzx+vt72DIDMzM2vbANGxaTCSXp9rgJA0GtgBuBs4B9g3J9sXOLtemd0cZmZmZm3r4lCJ44ApkkaRKnNOiYi/SroaOEXS/sADwB71duQgyMzMzAojIm4FNqyy/ClgQjP7chBkZmZmbSviXeQdBJmZmVnbfO8wMzMzs4JwTZCZmZm1rXj1QA6CzMzMrAOK2CfIzWFmZmbWl1wTZGZmZm0rYsdoB0FmZmbWtuKFQG4OMzMzsz7lmiAzMzNrWxE7RjsIMjMzs7ZFARvE3BxmZmZmfck1QWZmZtY2N4eZmZlZXyriJfJuDjMzM7O+5JogMzMza1vx6oEcBJmZmVkHuDnMzMzMrCBcE2TDyjd++jW22GEznnlyFhMnfAqANd+6Bgf/+KssvvhizHzoMb73xR/ywnMv9LikZiPHffc/xNcO/9Grjx96ZCZf/NTH+fieH+CEU8/mpNPPZdSoUWyzxbs4+Av797CkNpz56jCzNl1wyoWcedzZHPqLb7y67OtHHcxvv/d7brnmVt6z5y7s9bmP8IejJveukGYjzJtWW4XTp/wGgFdeeYXtd/84E7bdgutuvIVLr7yGM/70WxZZZBGeemZWbwtqw5oHSzRr0y3X3sbsWbNfs+yNa67KLdfcCsANV9zItu/ZphdFM+sL19wwnVXfMI6VV1qRk886j/33+QiLLLIIAMsvO6a3hTPrsMIEQZIWl/RtScfkx2tLel+vy2VD7757ZrDVTlsAMP592zJ25df3uERmI9ffpl7Ge3bYFoAZDzzMjbfczl6fPpCJX/gfbrvrnh6XzoazgQ5O3VKYIAg4DngZ2Dw/fgj4fq3Ekg6QdIOkG2Y+/3A3ymdD5McHHcUHJu7GMX/7HYsvMZq5c+f1ukhmI9LcuXOZduW17LT91kBqGpv93+c4cdLRHPyFT/G1b/+IiOI1eVh3RAf/uqVIfYLWjIg9Je0FEBEvSlKtxBExCZgEsM0bJvhdW2AP/PtBDt479RFaZY1V2HzCZj0ukdnIdMU1N7Dum9dkheWWBWDFsSuww7ZbIol3vHUdJPHMrGdZzs1iNkIUqSZojqTR5PGYJK1JqhmyEW7M8mMAkMQnvvIxzj7+3N4WyGyEOv/iabxnx/GvPt5+68257sbpAMx44CHmzpvHsmOW6U3hbNgrYnNYkWqCjgAuAFaVdAKwJTCxpyWyjjv8N4ex4ebrs8xyy3DaDX/huP+bwuglRvOBibsBcPn5V3D+yRf0uJRmI8+LL73E1dffzBFf//Kryz74vp341g+PZvd9PsvCCy/ED791MINUwFufGyhgU6mK1L4raXlgM0DANRHxZCPbuTnMrDem3nJMr4tg1rcWXmGNrkasH1/tgx37rj3+/jO6UvbCNIdJ2hJ4KSLOA8YAh0parbelMjMzM0h9VTo1dUthgiDgd8ALktYH/ge4H/hTb4tkZmZmkO4d1qmpW4oUBM2L1Ha3G/DLiPgFsFSPy2RmZmYFVaSO0f+V9E1gH2AbSaOAhXtcJjMzM8O3zRhqe5Iuid8/Ih4F3gAc1dsimZmZGfgS+SGVA5+flT1+APcJMjMzsxYVpiZI0maSrpf0nKQ5kl6R9Gyvy2VmZmbF7BhdmJog4NfAR4FTgY2BTwBr97REZmZmBhSzT1CRgiAi4l+SRkXEK8Bxkv7R6zKZmZlZMRUpCHpB0iLAdEk/AWYCS/S4TGZmZkZ3OzR3SmH6BAEfJ5X3i8DzwKrAh3paIjMzMwMgIjo2dUthaoIi4v58F/lxEfGdXpfHzMzMiq0wNUGS3g9MJ91JHkkbSDqnp4UyMzMzoJhXhxUmCAKOBN4FzAKIiOnA6j0rjZmZmb3KgyUOrXkR8aykXpfDzMzMKvgS+aF1u6S9gVGS1ga+DPgSeTMzM2tJkZrDvgS8jXT/sBOBZ4EDe1kgMzMzS4rYJ6gQNUH5jvHnRMQOwGG9Lo+ZmZm9Vjcvbe+UQtQE5RGiX5C0TK/LYmZmZiNDIWqCspeA2yRdTBosEYCI+HLvimRmZmZQzBGjixQEnZcnMzMzG2a6dXWYpFWBPwErkWKvSRHxC0nLASeThs+ZAXwkIp4ZbF9FCoJOA17KTWOlfkKL9rZIZmZm1mXzgIMj4iZJSwE35laiicDUiPixpEOAQ4BvDLajQvQJyqYCo8sejwb+3qOymJmZWZluXR0WETMj4qb8/3+Bu4A3ALsBU3KyKcDu9cpcpJqgxSLiudKDiHhO0uK9LJCZmZklnbw6TNIBwAFliyZFxKQq6VYHNgSuBVaMiJm5LDMlja2XT5GCoOclvbMU/UnaCHixx2UyMzOzDssBzwJBTzlJSwKnAwdGxOxW7ihRpCDoQOBUSY/kx+OAPXtXHDMzMyvp5iCHkhYmBUAnRMQZefFjksblWqBxwOP19lOYICgirpf0FmAdQMDdETG3x8UyMzMzunp1mIA/AHdFxM/KVp0D7Av8OM/PrrevwgRB2SakS98WAjaURET8qbdFMjMzsy7aEvg4aezA6XnZoaTg5xRJ+wMPAHvU21FhgiBJxwNrAtOBV/LiII0VYGZmZj000KXbZkTElaQWoWomNLOvwgRBwMbAW6OINycxMzMb4Yr45VykcYJuJ40OaWZmZta2ItUErQDcKek64OXSwojYtXdFMjMzM+ju1WGdUqQg6MheF8DMzMyqcxA0hCLisl6XwczMzEaOYR8ESfov1ftbCYiIWLrLRTIzM7MKRbxuadgHQRGxVK/LYGZmZoMrYnNYka4OMzMzM+uYYV8TZGZmZsNft26b0UkOgszMzKxtRewT5OYwMzMz60uuCTIzM7O2FbFjtIMgMzMza5ubw8zMzMwKwjVBZmZm1jY3h5mZmVlfKuIl8m4OMzMzs77kmiAzMzNr20ABO0Y7CDIzM7O2uTnMzMzMrCBcE2RmZmZtc3OYmZmZ9SU3h5mZmZkVhGuCzMzMrG1uDjMzM7O+5OYwMzMzs4JwTZCZmZm1zc1hZmZm1pfcHGZmZmZWEK4JMjMzs7ZFDPS6CE1zEGRmZmZtG3BzmJmZmVkxuCbIzMzM2ha+OszMzMz6kZvDzMzMzArCNUFmZmbWNjeHmZmZWV8q4ojRbg4zMzOzvuSaIDMzM2tbEW+b4SDIzMzM2uY+QWZmZtaXfIm8mZmZWUG4JsjMzMza5uYwMzMz60u+RN7MzMysIFwTZGZmZm1zc5iZmZn1JV8dZmZmZjbEJP1R0uOSbi9btpykiyXdm+fL1tuPgyAzMzNrW0R0bGrAZGCXimWHAFMjYm1gan48KAdBZmZm1raBiI5N9UTE5cDTFYt3A6bk/6cAu9fbj4MgMzMzG1YkHSDphrLpgAY2WzEiZgLk+dh6G7hjtJmZmbWtkzdQjYhJwKSO7bAGB0FmZmbWtmEwWOJjksZFxExJ44DH623g5jAzMzMbCc4B9s3/7wucXW8D1wSZmZlZ27o5WKKkk4DxwAqSHgKOAH4MnCJpf+ABYI96+3EQZGZmZm3rZJ+gunlF7FVj1YRm9uPmMDMzM+tLrgkyMzOztvneYWZmZtaXihgEuTnMzMzM+pJrgszMzKxtxasHAhWx+sr6i6QD8uihZtZFfu/ZSOfmMCuCRu4ZY2ad5/eejWgOgszMzKwvOQgyMzOzvuQgyIrAfRLMesPvPRvR3DHazMzM+pJrgszMzKwvOQgyMzOzvuQgyDpC0iuSpku6Q9Itkg6S5PPLrIskPdfrMpgViUeMtk55MSI2AJA0FjgRWAY4op2dSlooIua1Xzwza4Tfc9ZP/EvdOi4iHicNsvZFJaMkHSXpekm3SvpMKa2kr0u6Ldce/Tgvmybph5IuA74iaSNJl0m6UdKFksbldJ/O+7xF0umSFs/L95B0e15+eV5WswxmI42k8fl9dJqkuyWdIEl53SaS/pHfH9dJWkrSREmnSjoXuEjSEpL+mN8vN0vaLW+7uqQrJN2Upy3y8nGSLs+1wbdL2jov30nS1TntqZKW7NlBMavCNUE2JCLiP7k5bCywG/BsRGwiaVHgKkkXAW8Bdgc2jYgXJC1XtosxEbGtpIWBy4DdIuIJSXsCPwA+CZwREccASPo+sD/wK+BwYOeIeFjSmLy//auVISLuG9ojYdYzGwJvAx4BrgK2lHQdcDKwZ0RcL2lp4MWcfnNgvYh4WtIPgUsi4pP5PXSdpL8DjwM7RsRLktYGTgI2BvYGLoyIH0gaBSwuaQXgW8AOEfG8pG8ABwHf7dLzN6vLQZANJeX5TsB6kj6cHy8DrA3sABwXES8ARMTTZduenOfrAG8HLs4/ZEcBM/O6t+fgZwywJHBhXn4VMFnSKcAZdcrgIMhGqusi4iEASdOB1YFngZkRcT1ARMzO6wEuLnsP7gTsKulr+fFiwBtJAdWvJW0AvAK8Oa+/Hvhj/tFyVkRMl7Qt8FbSDw6ARYCrh+rJmrXCQZANCUlrkD4kHycFQ1+KiAsr0uxC7RsPP19KBtwREZtXSTMZ2D0ibpE0ERgPEBGflbQp8F5gev7ArloGsxHs5bL/XyF93ov67zlyug9FxD3lCSQdCTwGrE/qTvESQERcLmkb0nvueElHAc+QAqu92n8qZkPDfYKs4yS9Hvh/wK8jjcZ5IfC5/CsRSW+WtARwEfDJsr48y1XZ3T3A6yVtntMsLOlted1SwMy834+V5b9mRFwbEYcDTwKrDlIGs35yN7CypE0Acn+gaj+GLwS+VNaPaMO8fBlSTdIA8HFSzSySVgMez83TfwDeCVxDaoJbK6dZXNKbMRtGXBNknTI6V7kvDMwDjgd+ltcdS6qKvyl/qD5BqsG5INfS3CBpDnA+cGj5TiNiTm7C+qWkZUjn7M+BO4BvA9cC9wO3kYIigKNyfwUBU4FbgFurlaGTB8BsuMvvpz2BX0kaTeoPtEOVpN8jvc9uze+XGcD7gN8Cp0vaA7iU+bVH44H/kTQXeA74RO7DNxE4KffDg9RH6J9D8NTMWuLbZpiZmVlfcnOYmZmZ9SUHQWZmZtaXHASZmZlZX3IQZGZmZn3JQZCZmZn1JQdBZtaSfL+pyNPEGmlK66d1t3TDi4+D2fDkcYLMOkzSYONOPEcacfcm0i09To+IuV0p2AiU72t1YH44PSLO6llhzKxwHASZddeSeVoT2AO4TdKHI8IDyLVmDHBE/n8KcFbPSmJmheMgyGxofaDi8bLAFqTbfIwG3kG6OeyGFTeQHREiQvVTmZn1hoMgsyFUo3nmOEk/B6YBK5Duzv2NPJmZWZe4Y7RZD0TEHbz2Pmkf7lVZzMz6lYMgs945r+z/NSQtXnogaXLZFUWr52UflHSOpAckzanVAVvS5pJ+J+lOSbMkvZS3OVnSexstnKT3STpX0qN5HzMknSBp8yb20fBVUZLeLOknkq6X9ISkuZKelXSTpN9ImlB2V/PV8/O/r2wX+5blVz6tXiO/FSQdJumK/Bzn5HyvkPR1SUtV267KflaT9CtJ/5L0oqTH8z4+U+MO7WY2TPgNatY7T1Q8HgO8UCXdopLOYMH+Ra8haQngWOCjVVavmqePSDoP2Csi/ltjP6OAPwD7VqxaLU8flfRN4PHBytOoHCgcBXwJGFWxemlgwzx9nnS38ss6kOdE4JdAZaCzArBVng6S9IGIuHqQ/ewO/BlYomzxYsDr8z72kfT+dstrZkPDQZBZ77y+4vHsGumOBt4N/Bs4HrgHWBzYtpRA0qLA34HN8qIHgJOAO4CXgbWATwDrAO8FzpK0Y0QMVMnvl8wPgOaQrrq6EhgA3gXsD/wvHbgSK9fsnA7smhe9kvd7KSnIWhxYF9gZ2AAodbR+nBQUjgV+n5ddmste6TXBmqSvAD/PD1/O+V8BPAUsB+wC7AasCPxd0iYRcWeVsm8JnAIsnBddBZyc81uddAy3Av446EEws96JCE+ePHVwAqI01Un36bK091Wsm1y+H9KX7SKD7OvosrS/q5aW9GU9pSzdZ6uk2ZoU7ATwDLBRlTTrADMryjexzrGYVmP918vS3A+8Y5DnuBGwWsWy1cu2n9zAa7MRMDenvxtYu0a695ICwACurbJ+VN6+lPd3q6RZhBQUlR+nqsfBkydPvZncJ8isByS9BfhB2aLTBkn+ELBfRMypsa9xpKYigKkR8blqaSMNyvgp4D950UFVdncw82tbDoyIG6vs5568n7ZIWpL5V8TNAd4XEbfVSh8RN0bE/W1mewSpBvzlnN+9NfI6D/hxfvguSVtUJHk/KRiEFNgcXmUfc4D9SLVyZjYMOQgyG0KSdq+YJkqaBNzI/OawR4CfDLKbP0bE84Os/wip1gHgp4OVJwdCJ+eHa5d3Gs5Nau/ODx8n9XWptZ/zgLsGy6sB7yY1PwGcOFgA1AmSliXV8ACcHRH/qrNJ+fPfqWJdef+smsc8Il4AftNwIc2sq9wnyGxonVln/V3AHhFR2Um63BV19rF12f9jc2fdwSxb9v+6wIz8//rMD6amRcQrdfYzNW/fqq3K/j+njf00akvm//B7qYHjtHDZ/5XPc5M8HyD1RRrM1IZKZ2Zd5yDIrLueJ9Wy3EwKkE6NiJfrbPNwnfWrl/0/ucnylAdEK5f9X6+WpNE0g1ml7P92a5UasXrZ/5/IU6OWrXhcOlaP1qmlg/aPk5kNEQdBZkMoOnPbiBfrrF+mjX0vUvb/kmX/V7tUv1K9L/96li77/7k299WITh0nmH+sunGczGyIOAgyK75SADEPGB0R89rcD6RL0+tZon6SQZUPCbBkzVSdU/78JkbElDb3tQzdOU5mNkTcMdqs+ErNZQsBb25jP4+U/b9WA+kbSTOYh8r+b6dvUaPKmxXf1ua+SsdqpTxI5WDaPU5mNkQcBJkVX/kIyoOOKl3HLaRL1QG2zSNHD2b7NvKC13b43rVmqsGVD/ZYr+nxctJYPQC7SWrn8++6PH8daRTrwUxoIx8zG0IOgsyK7y/MD16+KmmlVnaSO2ifnx+uCOxdK62kdwNvbSWfMn8Dns7/7y3pHS3so7yJa9AamYh4HLggP3wzaeTrVpVf9VdtvCUAJI0GPtdGPmY2hBwEmRVcRDwI/Co/XB64UFLNJhglEyQdVmV1+Zg3v5C0QZXt1ybdW6wt+aqq0oCEiwDnDhYISdpA0moV+3gaeDY/3KB0g9VBfIs0YjTAryTtM1hiSW+UdJSksRWr/kq6fQnA9pIWGCxR0sKk47R6nTKZWY8oouqNqM2sReV3d2/16jBJk5l//643RcSMOukXJtWslJpe5gJnk5qAHiWNebMiaSygHUmXeE+NiB2q7Os3zB+B+mWq3ztsCdI9vnbP6faLiMlV9lU6FpdFxPgq65X3U37vsDOBaaShBEaTRmbeCdgY2C4iplXso/zmsqcCZwCzypJcFhEvlqXfHziG+c1n00nH6l/5+Y4B3kIaV+hdOd2qEVHeh6l077BLmT+e0JXMv3fYasBEUm3ZmWXlq3oczKw3HASZdVgvgqC8zSKkmpzPseDd2Kv5U0RU3im+dBf5P1J7HJ0B4BDgCeC4vKylICinWZh0Q9PPUr92etuIuLxi+w2Af5ACpmoWOH75zu7HkALDep4C3hIRT1Yp+wdIN7Wt1RR3BSnAeyY/dhBkNoy4OcxshIiIORHxJVItxo+Ba0mByjzSeDb3kfr8HAqsVy0Ayvt5Ja97P3Be3sfLzL8z/VYRcVQHyz03Ir5AqqX6BXAbqSbnlTy/kdTct01lAJS3n066MeqxpCaqumP3RMS5wJtIgdc5wIOk8ZjmkJ7v1TnP9wMrVwuA8n7OJF1p9mvSPdleBp4k3VH+c8D2ETGrXnnMrDdcE2RmZmZ9yTVBZmZm1pccBJmZmVlfchBkZmZmfclBkJmZmfUlB0FmZmbWlxwEmZmZWV9yEGRmZmZ9yUGQmZmZ9SUHQWZmZtaXHASZmZlZX3IQZGZmZn3p/wPp4AXWOxLt2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_coin = 'ADA'\n",
    "pretrained_model_coin = 'BTC'\n",
    "\n",
    "create_conf_matrix(preds, LSTM_ranged_validation_outputs, target_coin, pretrained_model_coin, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
